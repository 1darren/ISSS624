---
title: "Take-home Exercise 1"
editor: source
---

# 0. Goals & Objectives.

On this page, we define Exploratory Spatial Data Analysis (ESDA) to understand spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

::: callout-important
## Important Note

Due to the nature of EDA and Data Analysis, parts of this page have been Collapsed or placed behind tabs, to avoid excessive scrolling.
:::

## 0.1 Motivation

Public transport is a key concern for residents in land-scarce, population-dense Singapore. With [COEs](https://onemotoring.lta.gov.sg/content/onemotoring/home/buying/upfront-vehicle-costs/certificate-of-entitlement--coe-.html) reaching record highs and [authorities announcing the termination of bus services](https://www.todayonline.com/singapore/bus-service-167-30-minute-breaks-commuters-lta-2314221), there is no better time to understand the public transport network and systems in Singapore.

By understanding and modelling patterns of public transport consumption - including specifically Local Indicators of Spatial Autocorrelation (LISA), insights can be provided to both public and private sector to formulate more informed decisions that for the benefit of the public, and not just for profit.

# 1. Geospatial Data Wrangling

This study was performed in R, written in R Studio, and published using Quarto.

## 1.1 Import Packages

This function calls `pacman` to load sf, tidyverse, tmap, knitr packages;

-   `tmap` : For thematic mapping; powerful mapping package
-   `sf` : for geospatial data handling, but also geoprocessing: buffer, point-in-polygon count, etc
    -   batch processing over GIS packages; can handle tibble format
-   `sfdep` : creates space-time cube, EHSA; replaces spdep
-   `tidyverse` : for non-spatial data handling; commonly used R package and contains `dplyr` for dataframe manipulation
-   `mapview` : interactive plotting & manipulation
-   `RColorBrewer` : custom colour palettes for manipulation

```{r}
pacman::p_load(tmap, sf, sfdep, tidyverse, mapview, RColorBrewer)
```

## 1.2 Import Data

### 1.2.1 `Geospatial` Load Bus Stop Data

-   First, we load `BusStop` shapefile data from [LTA Datamall](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html).
-   `st_read()` is used to import the ESRI Shapefile data into an `sf` dataframe

```{r}
#| code-fold: true
#| code-summary: "show code"
raw_bus_stop_sf <- st_read(dsn = "data/geospatial", 
                 layer = "BusStop") 
head(raw_bus_stop_sf)
```
-   We check the coordinate reference system with `st_crs()`; 

::: {.callout-warning  collapse="true"}
## !LONG! st_crs readout
```{r}
#| code-fold: true
#| code-summary: "show code"

st_crs(raw_bus_stop_sf)
```
:::

- We see that although the projection is SVY21, the CRS (coordinate reference system) is EPSG 9001, which is incorrect; 
- We thus use `st_set_crs()` to set it to 3414, which is the [EPSG code for SVY21](https://epsg.io/3414)
    - we then use `st_crs()` to confirm it is the correct EPSG code

::: {.callout-warning  collapse="true"}
## !LONG! st_crs readout after st_transform
```{r}
#| code-fold: true
#| code-summary: "show code"

raw_bus_stop_sf <- st_set_crs(raw_bus_stop_sf, 3414)

st_crs(raw_bus_stop_sf)
```
:::

- We now do a quick plot to quickly visualize the bus stops;
    - `qtm()` is a wrapper to do a quick, simple plot using `tmap` without defining arguments
    - we use `tmap_mode("plot")` to set the map as a static image, rather than as an interactive map, in order to save processing.

```{r}
#| code-fold: true
#| code-summary: "show code"

tmap_mode("plot")
qtm(raw_bus_stop_sf)

```
### 1.2.2 Visualizing within Singapore's Administrative National Boundary

- This image is hard to read; we can vaguely discern Singapore's Southern coastline, but it can be hard to visualize
- I have sourced and downloaded supplemental data about Singapore's Administrative National Boundary ("SANB") from [igismap.com](https://map.igismap.com/gis-data/singapore/administrative_national_boundary) as a base layer for visualization;
    - We set `tmap_mode("view")` to allow us to scroll and confirm the SARB boundaries
    - As before, we use `st_read()` to load the shapefile data, and `st_transform()` to ensure the projection is correct
        - We use `tm_shape() + tm_polygons()` to map a grey layer of the SARB boundaries;
        - On top of which, we layer `tm_shape() + tm_dots()` to show the bus stops. 

```{r}
#| code-fold: true
#| code-summary: "show code"

sanb_sf <- st_read(dsn = "data/geospatial", 
                 layer = "singapore_administrative_national_boundary") %>%
  st_transform(crs = 3414)

tmap_mode("view")
tm_shape(sanb_sf) +
  tm_polygons() + 
  tm_shape(raw_bus_stop_sf) + 
  tm_dots()

## Additional data from: Data.gov.sg, https://beta.data.gov.sg/datasets/d_02cba6aeeed323b5f6c723527757c0bc/view
```
::: {.callout-note}
## Does the map look skewed to the right?

That's because the Singapore National Administrative Boundaries map includes [Pedra Branca](https://en.wikipedia.org/wiki/Pedra_Branca,_Singapore), the much-disputed outlying island and easternmost point of Singapore. 

It's an amusing artifact here, but will not be involved in further analysis later.

:::

- We note there are a number of bus stops outside Singapore's boundaries;
  Specifically, three bus stops in a cluster just outside the Causeway, and one further North.
- We perform several steps to isolate & check the data;
    - we use `st_filter()` to find bus stops within Singapore's Administrative National Boundaries, and create `sg_bus_stop_sf` for future use 
    - to check what bus stops have been dropped, we use `anti_join()` to compare `raw_bus_stop_sf` with `sg_bus_stop_sf`. We use `st_drop_geometry` on both `sf` dataframes to

    
```{r}
#| code-fold: true
#| code-summary: "show code"
sg_bus_stop_sf <- st_filter(raw_bus_stop_sf, sanb_sf)
anti_join(st_drop_geometry(raw_bus_stop_sf), st_drop_geometry(sg_bus_stop_sf))

```
- We see there are in fact 5 bus stops outside of Singapore (including the defunct [Kotaraya II Terminal](https://landtransportguru.net/kotaraya-ii-bus-terminal/)) that have been removed, which means our data cleaning was correct.

## 1.3 Geospatial Data Cleaning
### 1.3.1 Removing Duplicate Bus Stops

- But, do we need to do more data cleaning?
- We use `length()` to find the total number of raw values in the `$BUS_STOP_N` column of `sg_bus_stop_sf`
    - We then compare this to `length(unique())` to find the unique values
- And, indeed, we find there are 16 bus stops that are repeated; 


```{r}
cat("Total number of rows in sg_bus_stop_sf\t\t: ", paste0(length(sg_bus_stop_sf$BUS_STOP_N)))
cat("\nTotal unique bus stop IDs in sg_bus_stop_sf\t: ", paste0(length(unique(sg_bus_stop_sf$BUS_STOP_N))))
cat("\nRepeated bus stops\t\t\t\t:   ", paste0(length(raw_bus_stop_sf$BUS_STOP_N) - length(unique(raw_bus_stop_sf$BUS_STOP_N))))

```


-   It appears there are 16 datapoints that are specifically repeated; let's identify the bus stop numbers with repeated rows:
    -   First we use `filter()` with a pipe mark (using `or` condition) to identify repeated bus stop numbers (i.e. `$BUS_STOP_N`)
    -   We sort them in ascending order using `arrange()`; then, using `group_by()` and `row_number()` we add row numbers based on `$BUS_STOP_N` to a new column using `mutate()`

```{r}
#| code-fold: true
#| code-summary: "show code"
repeated_df <- sg_bus_stop_sf %>%
  filter(duplicated(BUS_STOP_N) | duplicated(BUS_STOP_N, fromLast = TRUE)) %>% 
  arrange(BUS_STOP_N) %>%
  group_by(BUS_STOP_N) %>%
  mutate(RowNumber = row_number())

repeated_df
```

- From examination, there are 32 bus stops sharing 16 bus stop numbers -- 16 pairs of bus stops sharing the same number.
- Let's examine these bus stop pairs on the map;
    -   we use `mapview()` to display these repeated bus stops on the map
    -   we use `col="BUS_STOP_N"` with `palette="Spectral` to give each pair of bus stops an individual colour 

```{r}
#| code-fold: true
#| code-summary: "show code"

tmap_mode("plot")
tm_shape(sanb_sf) +
  tm_polygons() + 
  tm_shape(repeated_df) + 
  tm_dots(col = "BUS_STOP_N", palette = "Spectral")
```

- After confirming with Prof Kam, we will simply drop the second instance of the rows.
    - we use `duplicated()` to identify rows with repeated values of `$BUS_STOP_N`; duplicated rows will return `TRUE` while all other rows will return `FALSE`
    - We use `!` to invert the values, so only the unduplicated rows will return `TRUE`.
    - We then use square brackets `[]` to index `sg_bus_stop_sf` based on the rows, and return only the unduplicated rows;
    
```{r}
#| code-fold: true
#| code-summary: "show code"
sg_bus_stop_sf <- sg_bus_stop_sf[!duplicated(sg_bus_stop_sf$BUS_STOP_N), ]
head(sg_bus_stop_sf)
```




::: {.callout-warning  collapse="true"}
## !LONG! Alternative manual cleaning steps;

I was unable to take Prof Kam's Data Analytics Lab, but I know of his fervour and attention to detail. I believe in informed choices, and so I performed manual cleaning with the following steps:
    - Remove the rows with lowercase names, as most `$LOC_DESC` are in strict uppercase
    - Remove the rows with `NA` `$LOC_DESC`
    - Remove the row with `NIL` `$LOC_DESC`
    - For remaining rows, drop second entry 
    - Retain remaining rows
- After this, we just run the same steps on `sg_bus_stop_sf` or perform an anti-join. 
    
However, after clarification with Prof Kam, we just drop the second entry.
My code is shown below for extra gratification

```{r}
#| code-fold: true
#| code-summary: "show code"

drop_second_stop = c("43709", "51071", "53041", "52059", "58031", "68091", "68099", "97079")
rows_to_retain_df <- repeated_df %>%
  filter(
    case_when(
      BUS_STOP_N == "11009" & grepl("[a-z]", LOC_DESC) ~ FALSE,
      BUS_STOP_N == "22501" & grepl("[a-z]", LOC_DESC) ~ FALSE,
      BUS_STOP_N == "77329" & grepl("[a-z]", LOC_DESC) ~ FALSE,
      BUS_STOP_N == "82221" & grepl("[a-z]", LOC_DESC) ~ FALSE,
      BUS_STOP_N == "62251" & grepl("[a-z]", LOC_DESC) ~ FALSE,
      BUS_STOP_N == "96319" & grepl("[a-z]", LOC_DESC) ~ FALSE,

      BUS_STOP_N == "47201" & is.na(LOC_DESC) ~ FALSE,

      BUS_STOP_N == "67421" & BUS_ROOF_N == "NIL" ~ FALSE,
      BUS_STOP_N %in% drop_second_stop & RowNumber == 2 ~ FALSE,

      TRUE ~ TRUE
    )
  )

rows_to_retain_df$LOC_DESC  = toupper(rows_to_retain_df$LOC_DESC)

print("Printing rows to retain:")
rows_to_retain_df
```


- If we run the steps from above, we can see that there are no repeated bus stops.

```{r}
cat("Total number of rows in sg_bus_stop_sf\t\t: ", paste0(length(sg_bus_stop_sf$BUS_STOP_N)))
cat("\nTotal unique bus stop IDs in sg_bus_stop_sf\t: ", paste0(length(unique(sg_bus_stop_sf$BUS_STOP_N))))
cat("\nRepeated bus stops\t\t\t\t:   ", paste0(length(sg_bus_stop_sf$BUS_STOP_N) - length(unique(sg_bus_stop_sf$BUS_STOP_N))))

```
## 1.4 Generating Hex Maps 

- We use `st_make_grid()` with `square = FALSE` to create the `hexagon` layer as defined in the study, which we name `raw_hex_grid`
    - We pass `cellsize = 500` to create the hexagons of necessary size. Prof Kam defined the apothem as 250m, which means the distance between opposite edges is double that, or 500m
        - I used `units::as_units` to pass 500 metres into the argument. I am still uncertain whether a length of 500m needs to be reprojected, or whether we need to do any further transformation.
- We use `st_sf()` to convert `raw_hex_grid` into an `sf` dataframe
    - `mutate()` is used here to create a `grid_id` column
    - We just use `st_transform()` in case we need to reproject the coordinate system, just in case.
- However, trying to visualize this right now just gives us a map full of hexagons.

```{r}
#| code-fold: true
#| code-summary: "show code"


raw_hex_grid = st_make_grid(sg_bus_stop_sf, cellsize = units::as_units(500, "m"), what = "polygons", square = FALSE) %>%
  st_transform(crs = 3414)
# To sf and add grid ID
raw_hex_grid <- st_sf(raw_hex_grid) %>%
  # add grid ID
  mutate(grid_id = 1:length(lengths(raw_hex_grid))) %>%
  st_transform(crs = 3414)

tmap_mode("plot")
qtm(raw_hex_grid)

```
- What we will need is to isolate only the hexes with bus stops in them.
    - We use `lengths(st_intersects())` to count the number of bus stops in each hex, and add that to a new column, `$n_bus_stops`
    - We then create `hexagon_sf` by filtering for only hexes with non-zero bus stops in each.
- We then plot these using the usual `tmap()` functions;
    - `tm_basemap()`is used to create a "basemap" layer underneath to orient our hexes.
    - We used [OneMapSG](https://www.onemap.gov.sg/) as our comprehensive map of Singapore; if you zoom in, you can actually count the number of bus stops in red on the map.

```{r}
#| code-fold: true
#| code-summary: "show code"


# Count number of points in each grid, code snippet referenced from: 
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r

raw_hex_grid$n_bus_stops = lengths(st_intersects(raw_hex_grid, sg_bus_stop_sf))

# remove grid without value of 0 (i.e. no points inside that grid)
hexagon_sf = filter(raw_hex_grid, n_bus_stops > 0)
# head(hexagon_sf)

tmap_mode("view")
tm_basemap(providers$OneMapSG.Grey) + 
  tm_shape(hexagon_sf) +
  tm_fill(
    col = "n_bus_stops",
    palette = "-plasma",
    style = "cont",
    
    breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),
    title = "Number of bus_stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of Bus Stops: " = "n_bus_stops"
    ),
    popup.format = list(
      n_bus_stops = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)


```

- There seem to be 2 regions of deep purple, centred over an area near, but not exactly over Pasir Ris and Choa Chu Kang MRTs.
- We perform some simple stats to count the total number of filtered hexes, and to see the maximum number of bus stops in a hex.

```{r}
#| code-fold: true
#| code-summary: "show code"
cat(paste("Total number of raw hexes is\t\t\t: ", nrow(raw_hex_grid), "\n"))
cat(paste("Total number of hexes (n_bus_stop > 1) is\t: ", nrow(hexagon_sf)), "\n")

cat("\nPrinting map_hexagon_sf:\n >> ")
hexagon_sf[hexagon_sf$n_bus_stops > 10, ]
```

### 0.3.1 Load Bus Trip Data

```{r}
#| code-fold: true
#| code-summary: "show code"


# odbus_2308 <- read_csv("data/aspatial/origin_destination_bus_202308.csv")
# 
# # Drop pt_type
# odbus_2308 <- select(odbus_2308, -PT_TYPE)
# # alternative way in read_csv df <- read_csv("data/aspatial/origin_destination_bus_202308.csv", col_types = "ccdcffd")
# 
# odbus_2308$ORIGIN_PT_CODE <- as.factor(odbus_2308$ORIGIN_PT_CODE)
# odbus_2308$DESTINATION_PT_CODE <- as.factor(odbus_2308$DESTINATION_PT_CODE) 
# glimpse(odbus_2308)
```

-   sanity check number of distinct bus stops over months

```{r}


# odbus_2309 <- read_csv("data/aspatial/origin_destination_bus_202309.csv")
odbus_2310 <- read_csv("data/aspatial/origin_destination_bus_202310.csv")

# Drop pt_type
# odbus_2309 <- select(odbus_2309, -PT_TYPE)
odbus_2310 <- select(odbus_2310, -PT_TYPE)
# alternative way in read_csv df <- read_csv("data/aspatial/origin_destination_bus_202308.csv", col_types = "ccdcffd")

# odbus_2309$ORIGIN_PT_CODE <- as.factor(odbus_2309$ORIGIN_PT_CODE)
odbus_2310$ORIGIN_PT_CODE <- as.factor(odbus_2310$ORIGIN_PT_CODE)



# cat("Confirm distinct origin bus stops 23-08: \n>> ", paste(length(unique(odbus_2308$ORIGIN_PT_CODE))))
# cat("Confirm distinct origin bus stops 23-09: \n>> ", paste(length(unique(odbus_2309$ORIGIN_PT_CODE))))
cat("Confirm distinct origin bus stops 23-10: \n>> ", paste(length(unique(odbus_2310$ORIGIN_PT_CODE))))


```

First we split out weekday and then perform mutate to group by

```{r}
# odbus_2310_weekday = odbus_2310 %>%
#  filter(DAY_TYPE == "WEEKDAY") %>%
#  mutate(PEAK = case_when(
#    TIME_PER_HOUR >= 6 &  TIME_PER_HOUR <= 9 ~ "MORNING PEAK",
#    TIME_PER_HOUR >= 17 &  TIME_PER_HOUR <= 20 ~ "AFTEROON PEAK",
#    TRUE ~ "Unknown"
#  ))
#cat("Confirm $DAY_TYPE only has `WEEKDAY` value: \n>> ", paste(unique(odbus_2310_weekday$DAY_TYPE)))
#odbus_2310_weekday



odbus_filtered <- odbus_2310 %>%
  mutate(PEAK = case_when(
    DAY_TYPE == "WEEKDAY" & TIME_PER_HOUR >= 6 &  TIME_PER_HOUR <= 9 ~ "WEEKDAY MORNING",
    DAY_TYPE == "WEEKDAY" & TIME_PER_HOUR >= 17 &  TIME_PER_HOUR <= 20 ~ "WEEKDAY AFTERNOON",
    DAY_TYPE == "WEEKENDS/HOLIDAY" & TIME_PER_HOUR >= 11 &  TIME_PER_HOUR <= 14 ~ "WEEKEND MORNING",
    DAY_TYPE == "WEEKENDS/HOLIDAY" & TIME_PER_HOUR >= 16 &  TIME_PER_HOUR <= 19 ~ "WEEKEND EVENING",
    TRUE ~ "Unknown"
  )) %>%
  filter(
    case_when(
      PEAK == "Unknown" ~ FALSE,
      TRUE ~ TRUE
    )) %>%
  group_by(ORIGIN_PT_CODE, PEAK) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

odbus_filtered <- odbus_filtered %>%
  pivot_wider(names_from = PEAK, values_from = TRIPS, values_fill = 0)


write_rds(odbus_filtered, "data/rds/odbus_filtered.rds")
head(odbus_filtered)
```

Sanity check, number of distinct bus stops?

```{r}

cat("Confirm distinct origin bus stops: \n>> ", paste(length(unique(odbus_2310$ORIGIN_PT_CODE))))
cat("\nConfirm distinct destination stops: \n>> ", paste(length(unique(odbus_2310$DESTINATION_PT_CODE ))))

cat("\nConfirm distinct bus stops in `bus_stop_sf`: \n>> ", paste(length(unique(sg_bus_stop_sf$BUS_STOP_N))))


# odbus_2310_copy <- odbus_2310 %>%
#   rename(BUS_STOP_N = ORIGIN_PT_CODE)
# 
# non_hexagon_sf <- anti_join(bus_stop_sf, odbus_2310_copy, by = "BUS_STOP_N")
# 
# cat("\nConfirm distinct bus stops in `non_hexagon_sf`: \n>> ", paste(length(unique(non_hexagon_sf$BUS_STOP_N  ))))
# 
# mapview_non_hexag = mapview(non_hexagon_sf, cex = 3, alpha = .5, popup = NULL)
# mapview_non_hexag
# 
# distinct_odbus <- distinct(select(odbus_2310, ORIGIN_PT_CODE)) #5073
# distinct_busstop <- distinct(select(bus_stop_sf, BUS_STOP_N)%>%
#   st_drop_geometry()) #5145
# 
# anti_join(distinct_odbus, distinct_busstop, by=c("ORIGIN_PT_CODE" ="BUS_STOP_N")) # 60
# anti_join(distinct_busstop, distinct_odbus, by=c("BUS_STOP_N" = "ORIGIN_PT_CODE")) #132
```

-   Test to reproduce `01013` bus stop with 841 trips on weekday mornings

```{r}
#| code-fold: true
#| code-summary: "show code"
subset_df <- odbus_2310 %>%
  filter(ORIGIN_PT_CODE == '01013') %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6) %>%
  filter(TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR, YEAR_MONTH) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS), .groups = 'keep')
head(subset_df)
180 + 138 + 254 + 269
```

## Create bus_stop_hexgrid_id

-   Combine hexagon_sf with bus_stop_sf

```{r}
#| code-fold: true
#| code-summary: "show code"

bus_stop_hexgrid_id <- st_intersection(sg_bus_stop_sf, hexagon_sf) %>%
  select(grid_id, BUS_STOP_N) %>%
  st_drop_geometry()

cat("\nNumber of bus stops\t:", length(unique(bus_stop_hexgrid_id$BUS_STOP_N)))
cat("\nNumber of hexgrids\t:", length(unique(bus_stop_hexgrid_id$grid_id)))

head(bus_stop_hexgrid_id)
```

## Combine bus_stop_hexgrid_id with trip details

-   Combine bus_stop_hexgrid_id with odbus_filtered

```{r}
#| code-fold: true
#| code-summary: "show code"
grid_trips_df <- left_join(odbus_filtered, bus_stop_hexgrid_id, 
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  select(grid_id, 
         `WEEKDAY MORNING`,
         `WEEKDAY AFTERNOON`,
         `WEEKEND MORNING`,
         `WEEKEND EVENING`)  %>%
  group_by(grid_id) %>%
  summarise(
    WEEKDAY_MORNING_TRIPS = sum(`WEEKDAY MORNING`), 
    WEEKDAY_AFTERNOON_TRIPS = sum(`WEEKDAY AFTERNOON`), 
    WEEKEND_MORNING_TRIPS = sum(`WEEKEND MORNING`), 
    WEEKEND_EVENING_TRIPS = sum(`WEEKEND EVENING`)
    )
head(grid_trips_df)
```

## Left join back to hexagon_df

```{r}
#| code-fold: true
#| code-summary: "show code"
hexagon_sf_2 <- left_join(hexagon_sf, grid_trips_df, 
            by = 'grid_id' ) %>%
  mutate(
    WEEKDAY_MORNING_TRIPS = ifelse(is.na(WEEKDAY_MORNING_TRIPS), 0, WEEKDAY_MORNING_TRIPS),
    WEEKDAY_AFTERNOON_TRIPS = ifelse(is.na(WEEKDAY_AFTERNOON_TRIPS), 0, WEEKDAY_AFTERNOON_TRIPS),
    WEEKEND_MORNING_TRIPS = ifelse(is.na(WEEKEND_MORNING_TRIPS), 0, WEEKEND_MORNING_TRIPS),
    WEEKEND_EVENING_TRIPS = ifelse(is.na(WEEKEND_EVENING_TRIPS), 0, WEEKEND_EVENING_TRIPS),
         )

head(hexagon_sf_2)

```

-   Now to try to do data analysis
-   In my defense, I emailed prof kam for DAL notes but he ignroed me for 6 months

```{r}
#| code-fold: true
#| code-summary: "show code"


summary(hexagon_sf_2$WEEKDAY_MORNING_TRIPS)


hist(hexagon_sf_2$WEEKDAY_MORNING_TRIPS, 
     main = "Histogram Example", 
     xlab = "WEEKDAY_MORNING_TRIPS", 
     col = "lightblue", 
     border = "black")



# Load the ggplot2 package
library(ggplot2)


trip_col_names <- c("WEEKDAY_MORNING_TRIPS", "WEEKDAY_AFTERNOON_TRIPS", "WEEKEND_MORNING_TRIPS", "WEEKEND_EVENING_TRIPS")

par(mfrow = c(2, 2))  # Set up a 2x2 layout
custom_breaks <- seq(0, 550000, by = 50000)

for (col in trip_col_names) {
  hist(hexagon_sf_2[[col]], main = col, col = "lightblue", border = "black",
       breaks = custom_breaks)
}

colnames(hexagon_sf_2)

```

## Map hexes on SIngapore

```{r}
#| code-fold: true
#| code-summary: "show code"

sarb_sf <- st_read(dsn = "data/geospatial", 
                 layer = "Subzone_Census2010") %>%
  st_transform(crs = 3414)
tmap_options(check.and.fix = TRUE)
qtm(sarb_sf)

## Additional data from: Data.gov.sg, https://beta.data.gov.sg/datasets/d_02cba6aeeed323b5f6c723527757c0bc/view
```

::: panel-tabset
## weekday_morning_vis

```{r}
#| code-fold: true
#| code-summary: "show code"

tm_shape(sarb_sf) +
  tm_polygons() + 
  tm_shape(hexagon_sf_2) + 
  tm_fill("WEEKDAY_MORNING_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Number of trips")
```

## weekday_afternoon_vis

```{r}
#| code-fold: true
#| code-summary: "show code"

tm_shape(sarb_sf) +
  tm_polygons() + 
  tm_shape(hexagon_sf_2) + 
  tm_fill("WEEKDAY_AFTERNOON_TRIPS", 
          style = "quantile", 
          palette = "Greens",
          title = "Dependency ratio")
```

## weekend_morning_vis

```{r}
tm_shape(sarb_sf) +
  tm_polygons() + 
  tm_shape(hexagon_sf_2) + 
  tm_fill("WEEKEND_MORNING_TRIPS", 
          style = "quantile", 
          palette = "Reds",
          title = "Dependency ratio")
```

## weekend_evenings_vis

```{r}
#| code-fold: true
#| code-summary: "show code"

tm_shape(sarb_sf) +
  tm_polygons() + 
  tm_shape(hexagon_sf_2) + 
  tm_fill("WEEKEND_EVENING_TRIPS", 
          style = "quantile", 
          palette = "Oranges",
          title = "Dependency ratio")
```
:::

```{r}
#| code-fold: true
#| code-summary: "show code"


# tm_shape(sarb_sf) +
#   tm_polygons() + 
#   tm_shape(hexagon_sf_2) + 
#   tm_fill("WEEKDAY_MORNING_TRIPS", 
#           style = "cont", 
#           palette = "viridis",
#           breaks = custom_breaks,
#           title = "Dependency ratio")
# tm_shape(sarb_sf) +
#   tm_polygons() + 
#   tm_shape(hexagon_sf_2) + 
#   tm_fill("WEEKDAY_AFTERNOON_TRIPS", 
#           style = "cont", 
#           palette = "viridis",
#           breaks = custom_breaks,
#           title = "Dependency ratio")
# tm_shape(sarb_sf) +
#   tm_polygons() + 
#   tm_shape(hexagon_sf_2) + 
#   tm_fill("WEEKEND_MORNING_TRIPS", 
#           style = "cont", 
#           palette = "viridis",
#           breaks = custom_breaks,
#           title = "Dependency ratio")
# tm_shape(sarb_sf) +
#   tm_polygons() + 
#   tm_shape(hexagon_sf_2) + 
#   tm_fill("WEEKEND_EVENING_TRIPS", 
#           style = "cont", 
#           palette = "viridis",
#           breaks = custom_breaks,
#           title = "Dependency ratio")

```

## Plot Weekday Morning

```{r}
#| code-fold: true
#| code-summary: "show code"


# mapview(hexagon_sf_2, zcol="WEEKDAY_MORNING_TRIPS", cex = 3, alpha = .5, popup = NULL)

```

## Plot Weekday Afternoons

```{r}
#| code-fold: true
#| code-summary: "show code"


# mapview(hexagon_sf_2, zcol="WEEKDAY_AFTERNOON_TRIPS", cex = 3, alpha = .5, popup = NULL)

```

## Plot Weekend Morning

```{r}
#| code-fold: true
#| code-summary: "show code"


# mapview(hexagon_sf_2, zcol="WEEKEND_MORNING_TRIPS", cex = 3, alpha = .5, popup = NULL)

```

## Plot Weekend Afternoons

```{r}
#| code-fold: true
#| code-summary: "show code"


# mapview(hexagon_sf_2, zcol="WEEKEND_EVENING_TRIPS", cex = 3, alpha = .5, popup = NULL)

```

::: callout-note
## **Quiz**: What statistical conclusion can you draw from the output above?

-   Using both fixed- and adaptive-distance neigbours generates similar results; values are largely in agreement
-   knn=8 feels like it's not very logical, but maybe there's not too much difference
:::

# 2. Create LISA

## Create Queen contiguity weight matrix hex

```{r}
#| code-fold: true
#| code-summary: "show code"
wm_hex <- st_contiguity(hexagon_sf_2, queen=TRUE)
summary(wm_hex)

```

## Create Queen contiguity

```{r}
#| code-fold: true
#| code-summary: "show code"
hex_no_nb <- c(307, 565, 730, 984, 1051, 1419, 1509, 1512, 1516, 1524)
hexagon_sf_2_drop_nonb <- hexagon_sf_2 %>%
  mutate(RowNumber = row_number()) %>%
  subset( !(RowNumber  %in% hex_no_nb))

vis_excluded_hexes <- tm_shape(sarb_sf) +
  tm_polygons() + 
  tm_shape(hexagon_sf_2) + 
  tm_fill("red") + 
  tm_shape(hexagon_sf_2_drop_nonb) + 
  tm_fill("green")
vis_excluded_hexes

```

## Drop JB Bus Stop

### Find Northernmost point: JB Bus stop

```{r}
#| code-fold: true
#| code-summary: "show code"
# coordinates <- st_coordinates(raw_bus_stop_sf$geometry)
# 
# # Find the index of the northernmost point
# northernmost_index <- which.max(coordinates[, 2])
# 
# # Extract the northernmost point
# northernmost_point <- raw_bus_stop_sf[northernmost_index, ]
# northernmost_point # 46239
```

### Identify the hex to drop

```{r}
#| code-fold: true
#| code-summary: "show code"
# jb_grid_id <- pull(bus_stop_hexgrid_id[bus_stop_hexgrid_id$BUS_STOP_N == 46239, 'grid_id']) #1767
# hexagon_sf_2_drop_jb <- 
#   subset(hexagon_sf_2, !(grid_id == jb_grid_id))

```

### Now we figure out distance; first find centroid

```{r}
#| code-fold: true
#| code-summary: "show code"


# longitude <- map_dbl(hexagon_sf_2_drop_jb$raw_hex_grid, ~st_centroid(.x)[[1]])
# latitude <- map_dbl(hexagon_sf_2_drop_jb$raw_hex_grid, ~st_centroid(.x)[[2]])
# coords <- cbind(longitude, latitude)
# # cat("Printing first 6 rows of `coords`:\n")
# # head(coords)
# 
# 
# k1_nn_obj <- st_knn(coords, k = 1)
# k1dists <- unlist(st_nb_dists(coords, k1_nn_obj))
# summary(k1dists)
```

-   2km is a huge distance -- we would enmesh hexes to about 4 hexes away
-   bus stops are

```{r}
#| code-fold: true
#| code-summary: "show code"

# check_dist <- st_nb_dists(coords, k1_nn_obj)
# which.max(check_dist) # 1523
# 
# 
# tm_shape(sarb_sf) +
#   tm_polygons() + 
#   tm_shape(hexagon_sf_2_drop_jb) + 
#   tm_fill("cyan") + 
#   tm_shape(hexagon_sf_2_drop_jb[1523,]) + 
#   tm_fill("orange")


```

### Find Northernmost point: Changi Naval Base Point

```{r}
#| code-fold: true
#| code-summary: "show code"
# coordinates <- st_coordinates(raw_bus_stop_sf$geometry)
# 
# 
# 
# # Find the index of the northernmost point
# easternmost_index <- which.max(coordinates[, 1])
# 
# # Extract the northernmost point
# easternmost_point <- raw_bus_stop_sf[easternmost_index, ]
# easternmost_point # 96439        
```

### Identify the hex to drop

```{r}
#| code-fold: true
#| code-summary: "show code"
# naval_base_grid_id <- pull(bus_stop_hexgrid_id[bus_stop_hexgrid_id$BUS_STOP_N == 96439, 'grid_id']) #1767
# hexagon_sf_2_drop_changi <- 
#   subset(hexagon_sf_2_drop_jb, !(grid_id == naval_base_grid_id))
# 
# longitude_2 <- map_dbl(hexagon_sf_2_drop_changi$raw_hex_grid, ~st_centroid(.x)[[1]])
# latitude_2 <- map_dbl(hexagon_sf_2_drop_changi$raw_hex_grid, ~st_centroid(.x)[[2]])
# coords_2 <- cbind(longitude_2, latitude_2)
# k1_nn_obj_2 <- st_knn(coords_2, k = 1)
# k1dists_2 <- unlist(st_nb_dists(coords_2, k1_nn_obj_2))
# summary(k1dists_2)
```

-   A much more manageable 1km; two hexes away. Let's work with this.

### Now we figure out distance; first find centroid

```{r}
#| code-fold: true
#| code-summary: "show code"
# hex_1km_nb <- st_dist_band(coords_2, lower = 0, upper = 1000.1)
# head(hex_1km_nb, 5)
# 
# hex_1km_wt <- st_weights(hex_1km_nb)
# 
# head(hex_1km_wt, 5)
  
```

### Calculate Local Moran's I

```{r}
#| code-fold: true
#| code-summary: "show code"


# localMI_day_morn <- local_moran(hexagon_sf_2_drop_changi$WEEKDAY_MORNING_TRIPS , hex_1km_nb, hex_1km_wt)
# 
# hexagon_sf_local_moran <- cbind(hexagon_sf_2_drop_changi,localMI_day_morn) 
```

### Identify the hex to drop

```{r}
#| code-fold: true
#| code-summary: "show code"
# local_moran_stats <- tm_shape(sarb_sf) +
#   tm_polygons() +
#   tm_shape(hexagon_sf_local_moran) +
#   tm_fill(col = "ii", 
#           style = "pretty",
#           palette = "RdBu",
#           title = "Local Moran Statistics") +
#   tm_borders(alpha = 0.5) +
#   tm_layout(main.title = "Local Moran Statistics")
# 
# local_moran_p <- tm_shape(sarb_sf) +
#   tm_polygons() +
#   tm_shape(hexagon_sf_local_moran) +
#   tm_fill(col = "p_ii", 
#           breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
#           palette="-Greens", 
#           title = "local Moran's I p-values") +
#   tm_borders(alpha = 0.5) +
#   tm_layout(main.title = "Local Moran's I p-values")
# 
# tmap_arrange(local_moran_stats, 
#              local_moran_p, 
#              asp=1, 
#              ncol=2)
```

-   But we only want to see the ones with p \< 0.05, so we need to do some cleaning

```{r}
#| code-fold: true
#| code-summary: "show code"


# hexagon_sf_local_moran_sig_only <- hexagon_sf_local_moran %>%
#   subset( !(p_ii  < 0.05))
# 
# tm_shape(sarb_sf) +
#   tm_polygons() +
#   tm_shape(hexagon_sf_local_moran) +
#   tm_fill("darkgrey") +
#   tm_shape(hexagon_sf_local_moran_sig_only) +
#   tm_fill(col = "ii", 
#           style = "pretty",
#           palette = "RdBu",
#           title = "Local Moran Statistics") +
#   tm_borders(alpha = 0.5) +
#   tm_layout(main.title = "Local Moran Statistics")

```

### Moran Scatterplot

```{r}
#| code-fold: true
#| code-summary: "show code"
# Create lag


# hexagon_sf_local_moran <- hexagon_sf_local_moran %>%
#   mutate(trips_lag = st_lag(hexagon_sf_local_moran$WEEKDAY_MORNING_TRIPS, hex_1km_nb, hex_1km_wt))
# 
# ggplot(hexagon_sf_local_moran, aes(WEEKDAY_MORNING_TRIPS, trips_lag)) +
#   geom_point() +
#   geom_vline(xintercept = mean(hexagon_sf_local_moran$WEEKDAY_MORNING_TRIPS), linetype = "dashed", color = "red", size = 1.2) +
#   geom_hline(yintercept = mean(hexagon_sf_local_moran$trips_lag), linetype = "dashed", color = "red", size = 1.5) +
#   labs(title = "Scatterplot Example", x = "X-axis", y = "Y-axis")

```

### Plot Local Moran's

```{r}
#| code-fold: true
#| code-summary: "show code"
# hexa_sig <- hexagon_sf_local_moran  %>%
#   filter(p_ii_sim < 0.05)
# 
# 
# tmap_mode("plot")
# tm_shape(sarb_sf) +
#   tm_polygons() + 
# tm_shape(hexagon_sf_local_moran) +
#   tm_fill("mean") +
#   tm_borders(alpha = 0.5)


```
