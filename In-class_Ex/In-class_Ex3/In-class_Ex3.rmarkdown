---
title: "In-class Exercise 3: Spatial"
date: "02 Dec 2023"
date-modified: "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning: false
editor: source
---


::: {.callout-note collapse="true"}
### Hidden: In-Class Lecture notes

## In-Class Lecture Notes

"In real world, there is no concept of equality." -- Prof Kam

```         

### Take-home Exercise notes:
- drop_NA() outside of region 
- do not save map as object class; will take very long
    - e.g. do not do map_name <- tmap_(...)
    - instead just call and render directly: tm_shape(...)    
- also consider change to tmap_mode("view") instead of `plot`

- exclude busstops in JB but retain causeway dataset 

- stick with tmap instead of mixing with mapview

### Learnings from Hands-on Ex03:

- Statistical method: cut away lowest 5% (cutoff < 5000 trips)
- Reveals a more focused map:
    - Westside, Jurong East/Clementi area: major transport nodes to adjacent mpsz subzone
    - Eastside, nexus around Tampines area extending to many related subzones
    - North-to-East: very long trips from N of island to E of island
    
    
- Understand: What are the factors affecting this flow?
    - Build explanatory models to understand factors that affect this flow 

### Concepts from Economic Geography / Retail Marketing: Trade Area Analysis

- Conditions for Spatial Flow 
    - Transferability: Willingness to travel for event (eg Concert)
    - Intervening Opportunity: Alternative travel options (eg Orchard vs JB)
    
- Travel costs: people willing to pay for transport (+lodgings) for 1-night concert

### In-Class Exercise 03

- Difficult if we consider bus-stop to bus-stop; too granular, single stop
    - That's why it's aggregated at subzone level;
    
- GENERAL FORMULATION:
    - [ Vi ] Available at origin; push factor
    - [ Wi ] Available at destination; pull factor
    - [ Sij ] Distance decay; distance of willingness to travel
    
- Vi, Wi can be one or multiple factors
- Interaction model Tij is thus a function of f(Vi, Wi, Sij)

- GRAVITY MODEL: Explain spatial interaction; i and j exert identical, opposite force on each other (as in gravity)
- POTENTIAL MODEL: Willingness to move for specific services eg 
- RETAIL MODEL: Delineate trade areas (fixed boundaries); eg people tend to shop within their regional boundaries instead of stepping out
    - since IRL the strict lines don't exist, we use probability 
    
- General formula can be easily formulated into a form for linear regression
    - Most of the time, relationship is nonlinear;
    - eg some goods, people are willing to pay over Beta: distance decay (eg concert) 
        - some goods are not worth travelling for (eg loaf of bread)
        - Beta looks like inverse relation (1/x)
    - Alpha & Lambda (propulsiveness/repulsiveness): similarly nonlinear, tend to be economic factors
        - looks like exponential, x^n 
- Use of generalised regression model in R

"The moral of the story is, not every relationship is linear."




 
```
:::

# 16. Calibrating Spatial Interaction Models with R

See Chapter 16: <https://r4gdsa.netlify.app/chap16>

-   When configuring, you need three types of data:

    -   `Flow data`: Prepared in Hands-on Ex03

    -   (Today): Calculate Tij formula by calculating Sij

## Overview

-   See also [In-Class Exercise 2: GLSA](In-class_Ex2_GLSA.html) and [In-Class Exercise 2: EHSA](In-class_Ex2_EHSA.html)

## 16.3 Getting Started - Import packages

-   `sp` Spatial Polygon package; computationally more efficient for large dataset

    -   Replaced by `sf` since 2015

-   `dt` for Dynamic tables

-   `performance` to calculate metrics to measure performance of model eg R\^2, MSE

-   `reshape2` handles matrices for distance matrix;

    -   Replaced by `tidyverse`, which focuses on handling dataframes but doesn't handle distance matrices so well

-   `ggpubr` for composing multiple plots into one

-   `tidyverse` loads a universe of packages, don't need to separately import `ggplot`, `tidyr`, `dplyr`


```{r}
pacman::p_load(tmap, sf, sp, DT,
               performance, reshape2,
               ggpubr, tidyverse)
```


## 16.5 Computing Distnace matrix

-   we use administrative boundaries of subzone for easier parsing, instead of bus stop centroid

-   `rds` saves the R object, preserving the classes;

    -   `mpsz` was `sf` `tibble` dataframe in Hands-on Ex03; here it is reproduced in the same class from previously loaded

    -   If we instead exported as shapefile, many details will be lost

    -   Alternatively, we could perform st_read from previous


```{r}
#| code-fold: true
#| code-summary: "show code"
mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```


-   Note that distance matrix is symmetriccal about the diagonal;

    -   Diagonal is always zero, as row_1 == col_1, row_2 == col_2, etc

    -   We treat intra-subzone as zero

    -   By default, function will infill as zero

### Convert back to `sp` dataframe

-   Revert to earlier `sp` dataframe for computational efficiency with matrices

    -   Technically now a `list` of data/polygon/proj4string; no longer a neat tibblr dataframe

        -   `data` table still exists; just a different object

        -   geometry now rendered in `polygon`

        -   In `tidyverse` , everything is a single dataframe

            -   To get specific column, need to call `mpsz_sp@data$column_name` i.e. need to call data table before calling column

-   this code chunk written without pipemarks ("a very un-`Tidy` way to write") to show alternatives


```{r}
#| code-fold: true
#| code-summary: "show code"
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp

# Alternative write:
# mpsz_sp <- mpsz %>%
# as.Spatial() 
```


ate

### 16.5.2 Use `spDists()` to compute distance matrix

-   Also possible with `sf` functions, but takes very long time, less efficient

-   `longlat = FALSE` as our data already has projection and has units

    -   If `TRUE`, will use great circle projection

-   Note that `dist` is a `"matrix" "array"` class

    -   Also, that rows & columns are not named with MPSZ codes


```{r}
#| code-fold: true
#| code-summary: "show code"
dist <- spDists(mpsz_sp, 
                longlat = FALSE)
# creates large matrix, 110224 cells (332 rows x 332 cols)

# preview to only show first 10x10 of matrix 
head(dist, n=c(10, 10))
```


### 16.5.3 Rename row/cols with labels:  

- Extract subzone names from original `mpsz` tibble



```{r}
#| code-fold: true
#| code-summary: "show code"

sz_names <- mpsz$SUBZONE_C
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)

head(dist, n=c(10, 10))

```


### Pivot matrix to long table 

- goal is to match structure of `SIM_data`;
    has `$ORIGIN_SZ`, `$DESTIN_SZ`, and (intrazonal) `$DISTANCE`
- `melt()`: old R version of `reshape()`;
    - converts row names, col names into Var1, Var2 as per below;
    - note that it is now 110224 rows, or 332 x 332 distance pairs
- typically, longdata is 
    
- IMPORTANT: Never sort!
    - Often the dataset is unlabelled;
    - We want to maintain the sequence for later labelling
    - Any sorting destroys the order and structure


```{r}
#| code-fold: true
#| code-summary: "show code"

distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)

```




### 16.5.5 Further cleaning 

- Find minimum distance; 
    - NOTE: This is simply a view, does not modify the underlying `distPair` dataframe


```{r}
#| code-fold: true
#| code-summary: "show code"
distPair %>%
  filter(dist > 0) %>%
  summary()

```

- Mysteriously, we use 50m 
    - Prof Kam says we are using a value lower than minimum inter-zonal distance
    - Interzonal distance is usually centroid-to-centroid, so not actually an accurate representation, as boundaries can connect with each other
    - We approximate; 173.8 is centroid-to-centroid distance, which means centroid-to-boundary distance is about half, or ~80
    - So we pick 50m as shorter 


```{r}
#| code-fold: true
#| code-summary: "show code"
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
distPair %>%
  summary()
```


- Rename cols and save as rds object for future analysis


```{r}
#| code-fold: true
#| code-summary: "show code"
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)

write_rds(distPair, "data/rds/distPair.rds") 

distPair
```




### 16.6 Import flow data

template


```{r}
#| code-fold: true
#| code-summary: "show code"

od_data <- read_rds("data/rds/od_data.rds")
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 
head(flow_data, 10)
```

```{r}
#| code-fold: true
#| code-summary: "show code"

flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)

flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)

flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```


- Now that we have distance matrix, we need propulsiveness/attractiveness
    - 25-64: "Economically active" age subgroup 
    - 7-12, 13-24: Primary school + secondary/tertiary students
- By and large, population lives in residential new towns;
    - Driving force for transport == journey to work, journey to school
- this is the cleaned data from `pop`, cleaned from `respopagesex2022.csv` via SingStat/Dept of Stats
    - Population Trends -> Singapore Residents by Planning Area/Subzone 2011-2020
    - We use "Single Year of Age" in order to define own age buckets
    
### Plot a chloropleth of GDPPC

- Left join to convert subzone names in `pop$SZ` to subzone code as in `mpsz$SUBZONE_N`
    - `mpsz` layer has subzone names AND subzone codes
    
    

```{r}
#| code-fold: true
#| code-summary: "show code"

pop <- read_csv("data/aspatial/pop.csv")

pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)

pop
```


- now we prepare origin, destination, and write RDS
    - note code pattern; we explicitly left_join twice; first `$ORIGIN_SZ` to `$SZ`, then `$DESTIN_SZ` to `$SZ`
    - this allows us to have origin dataset & destination dataset
    
- for morning peak: population at origin
    - at evening peak, usually is population at destination: people heading home after 
- accuracy is only 70-80% as transfers are not fully accounted for


```{r}
#| code-fold: true
#| code-summary: "show code"
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))

flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))

write_rds(flow_data1, "data/rds/SIM_data_out")
# NB: SIM_Data already provided, 

```



## 16.8 Use of Poisson Regression

-   `mutate` is functi


```{r}
#| code-fold: true
#| code-summary: "show code"

SIM_data <- read_rds("data/rds/SIM_data.rds")
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```



 One-step function using `sfdep`; a wrapper for `spdep` but writes output into `sf` dataframe


```{r}
#| code-fold: true
#| code-summary: "show code"

ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```



 One-step function using `sfdep`; a wrapper for `spdep` but writes output into `sf` dataframe


```{r}
#| code-fold: true
#| code-summary: "show code"

ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```




- feature engineering: converting `0` values to `0.99`
    - Explict change to make it fit into our algorithm --> feature engineering
    - Since Poisson regression uses log, log0 does not work; so we need to specifically engineering features to not be zero
    - All data prep before is model-agnostic, but this is model-specific value coercion 

- `glm()` has many types of regression, so we must define argument `family = poisson(link="log")`
    - hence poisson instead of linear regression
- note that though formula is negative for distance (e.g. - Beta ln dij), we  write the term as `log(dist)`; 
    - parameter estimate will be negative, eg log(dist) = -1.51..
    - Distance must be inverse (longer distance = less likely), thus when we check outputs, if log(dist) is not negative, something wrong
    - AIC: Akaike information critera to estimate fit between model and data
- we test various constrains/unconstrains to see which model works best

 One-step function using `sfdep`; a wrapper for `spdep` but writes output into `sf` dataframe


```{r}
#| code-fold: true
#| code-summary: "show code"

#SIM_data <- read_rds("chap16/data/rds/SIM_data.rds")
```

