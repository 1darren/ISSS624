---
title: "In-class Exercise 4: Spatial"
date: "09 Dec 2023"
date-modified: "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning: false
editor: source
---

::: {.callout-note collapse="true"}
### Hidden: In-Class Lecture notes

## In-Class Lecture Notes

"In real world, there is no concept of equality." -- Prof Kam

```         

### Take-home Exercise notes:
- drop_NA() outside of region 
- do not save map as object class; will take very long
    - e.g. do not do map_name <- tmap_(...)
    - instead just call and render directly: tm_shape(...)    
- also consider change to tmap_mode("view") instead of `plot`

- exclude busstops in JB but retain causeway dataset 

- stick with tmap instead of mixing with mapview

### Learnings from Hands-on Ex03:

- Statistical method: cut away lowest 5% (cutoff < 5000 trips)
- Reveals a more focused map:
    - Westside, Jurong East/Clementi area: major transport nodes to adjacent mpsz subzone
    - Eastside, nexus around Tampines area extending to many related subzones
    - North-to-East: very long trips from N of island to E of island
    
    
- Understand: What are the factors affecting this flow?
    - Build explanatory models to understand factors that affect this flow 

### Concepts from Economic Geography / Retail Marketing: Trade Area Analysis

- Conditions for Spatial Flow 
    - Transferability: Willingness to travel for event (eg Concert)
    - Intervening Opportunity: Alternative travel options (eg Orchard vs JB)
    
- Travel costs: people willing to pay for transport (+lodgings) for 1-night concert

### In-Class Exercise 03

- Difficult if we consider bus-stop to bus-stop; too granular, single stop
    - That's why it's aggregated at subzone level;
    
- GENERAL FORMULATION:
    - [ Vi ] Available at origin; push factor
    - [ Wi ] Available at destination; pull factor
    - [ Sij ] Distance decay; distance of willingness to travel
    
- Vi, Wi can be one or multiple factors
- Interaction model Tij is thus a function of f(Vi, Wi, Sij)

- GRAVITY MODEL: Explain spatial interaction; i and j exert identical, opposite force on each other (as in gravity)
- POTENTIAL MODEL: Willingness to move for specific services eg 
- RETAIL MODEL: Delineate trade areas (fixed boundaries); eg people tend to shop within their regional boundaries instead of stepping out
    - since IRL the strict lines don't exist, we use probability 
    
- General formula can be easily formulated into a form for linear regression
    - Most of the time, relationship is nonlinear;
    - eg some goods, people are willing to pay over Beta: distance decay (eg concert) 
        - some goods are not worth travelling for (eg loaf of bread)
        - Beta looks like inverse relation (1/x)
    - Alpha & Lambda (propulsiveness/repulsiveness): similarly nonlinear, tend to be economic factors
        - looks like exponential, x^n 
- Use of generalised regression model in R

"The moral of the story is, not every relationship is linear."




 
```
:::

# 4. In-Class Ex 4

## Overview

-   Geocoding
-   Geographically Weigted Poisson Regression

## 4.1 Import Packages

-   `httr` HTML features, communicate with webserver

-   `tidyverse` Data science work

-   `tmap` Visual plotting

-   `sf` Geospatial work

```{r}
pacman::p_load(tidyverse, sf, httr, tmap)
```

## 4.2 Geocoding

-   OneMap: Offer online API

    -   Reverse Geocoding: You provide geographical coordinates, they provide you info of that aare

    -   `Search`: We pass in details (eg Building, Address) and retrieve X/Y or Lat/Long

        -   LatLong is from 0 to 360

        -   X, y is in metres

        -   1 degree at equator is \>\>\> 1 degree at the pole; WGS84 is broadly useful but SVY21 is more accurate (Projected coordinate system, more accurate on-the-ground for distance
        
- Within Singapore context, we should look for datasets with postal code;
    - We can then use OneMap API to generate X/Y or LAT/LONG
    - If not, we can use street name + address + OneMap API
        
- Add `#| eval:false` to freeze the code block, to avoid re-running code during rendering; this makes recompiling HTML faster        

- Add `#| echo:false` or `#| message:false` to squelch readouts
        
```{r}

#| eval: false
url<- "https://www.onemap.gov.sg/api/common/elastic/search"
csv <- read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes <- csv$`postal_code`

found <- data.frame()
not_found <- data.frame()

for (postcode in postcodes){
  query <- list('searchVal'=postcode, 'returnGeom' = 'Y', 'getAddrDetails' = 'Y', 
                'pageNum'='1')
  res <- GET(url, query=query)
  
  if ((content(res)$found)!=0){
    found <- rbind(found, data.frame(content(res))[4:13])
    } else {
      not_found = data.frame(postcode)
    }
}


```

- if run correctly, Zeng Hua Secondary School is the missing school
- We save as CSV to do "backdoor" manual edit
    - manually google for lat/long, add in decimal degree (1.389279, 103.7651)
    - can build crawler instead to do this programmatically

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"

merged = merge(csv, found, by.x='postal_code', by.y='results.POSTAL', all=TRUE)
write.csv(merged, file="data/aspatial/schools.csv")
write.csv(not_found, file="data/aspatial/not_found.csv")


```

- import schoolcs.scv
- rename cols to LATITUDE LONGITUE
- retian only potla_code, school_name, lat, long

- when feeding arguments, always specify LONGITUDE then LATITUDE because of cartesian coordinates convention (x, y) 
- specify initial coords of initial untransformed data (WGS84, crs4326)

```{r}
#| code-fold: true
#| code-summary: "show code"

schools <- read_csv("data/aspatial/schools.csv") %>% 
       rename("latitude"= "results.LATITUDE",
              "longitude"= "results.LONGITUDE") %>%
  select(postal_code, school_name, latitude, longitude)
schools_sf <- st_as_sf(schools,
                       coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)

schools_sf
```

-   `rds` saves the R object, preserving the classes;

    -   `mpsz` was `sf` `tibble` dataframe in Hands-on Ex03; here it is reproduced in the same class from previously loaded

    -   If we instead exported as shapefile, many details will be lost

    -   Alternatively, we could perform st_read from previous

```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false
tmap_mode("view")
tm_shape(schools_sf) + 
  tm_dots() + 
  tm_view(set.zoom.limits = c(11, 14))
tmap_mode("plot")

```


- Point-in-polygon count
    - polygon & points should be in same projection, e.g. 3414
- Why use `st_intersects()` over `st_within()`?
    - can also; but intersection has same output 
    - use of `lengths()` to count number of schools within mpsz
    
    
- `business` dataset : SME businesses


```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false
mpsz <- st_read(dsn = "data/geospatial", layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)

mpsz$`SCHOOL_COUNT` <- lengths(
  st_intersects(
    mpsz, schools_sf))
mpsz
```


- `business` dataset : SME businesses


```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false
business_sf <- st_read(dsn = "data/geospatial", layer = "business") %>%
  st_transform(crs = 3414)

mpsz$`BUSINESSL_COUNT` <- lengths(
  st_intersects(
    mpsz, business_sf))
mpsz
```

- trick: plot base map of polygon map, before plotting dot map
    - this will place points, lines over polygn
- use `tmap_options(check.and.fix = True)` to close/reunite polygon
    - eg geometry not closed, from busstop
    
- business, school location are attractiveness, AT DESTINATOIN
    - trick: left join destin_sz = subzone c
    - if join on origin, will be propulsive
    
    
- for Poisson regression, we need to check for 0, coerce to 0.99
    - just a small number below 1

## Take Home Ex 2
- put together hands-on-exercise


- 325m: willingness of people to walk from home to bus stop/mrt is 750m 
- pick one peak;
    - weekday morn - go to work
    - weekday aft - go home
    - weekend/ph morn - go out
    - weekend eve - go home
    - edge case: people tend to go out on Friday nights, not Sunday nights; 
- attractiveness/propulsiveness is different


# IN-Class ex 4 


```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
pacman::p_load(tmap, sf, DT, stplanr,
               performance,
               ggpubr, tidyverse)
```

-
```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
flow_data <- read_rds("data/rds/flow_data_tidy.rds")

# note that RETAIL_COUNT is mislabelled, should really be BUSINESS_COUNT
glimpse(flow_data)
```

- steps: remove intrazonal trips
    - by definition, all attractiveness/propulsiveness within the zone is the same; not useful
    - we want to understand what makes people travel between zones
    
    
- write to RDS after data cleaning, to avoid re-running when fitting SIM model
    - also, clear environment of objects, to avoid storage
    - for rigour, clear cache regularly 
    
    
- 4 models under gravity
    - unconstrained
    - origin-constrained  : only have attractiveness factors (eg school, retail)
    - destination-constrained
    - doubly constrained
- previously, population: not valuable 
- distance still retained, as impedance;
- for origin/destination constrained, you don't need intercept -- so, he has formula = ... -1
    - na.action = na.exclude: failsafe drop NA 
    
- what we're looking at is log(SCHOOL_COUNT), log(RETAIL_COUNT), log(DIST)
    - ideally, low signif codes => significant factors
    - we also want to interpret the parameters correctly
        - log(DIST) should be negative -> by right, always inverse distance
        - attractiveness params should be positive, propulsiveness should be negative
        - contrast: CRIME RATE should be negative (we want lower crime rate)
        
        
- GLM does not provide r-squared
- we define a function, `CalcRSquared` to calculate R^2 for goodness of fit
    - base R has correlation function `cor()`
    - we square -- positive/negative correlation is possible
    
- output of GLM, `orcSIM_Poisson`, is a model object / list of 30 objects
    - some objects are:
        - `coefficients` for column/variables
        - `residuals`` errors for each interzonal flow <- can be joined to inter_zonal flow
        - `fitted.values` expected_Y based on model
        
- can be extracted using as_dataframe() with `orcSIM_Poisson$residuals`

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
CalcRSquared <- function(observed, estimated){
  r <- cor(observed, estimated)
  R2 <- r^2
  R2
}

# CalcRSquared( $trips, $fitted.values)


# performance_rmse(orcSIM_Poisson, normalized = False)
# get raw RMSE instead of normalised value 
```

- for doubly-constrained, "don't need to worry about intercept" don't need to -1
- use chap16#model-compariosn 
    - lowest RMSE si morebest
- multiplot if RMSE is large, scatter is larger
    - may want to drop that one massive outlier   




