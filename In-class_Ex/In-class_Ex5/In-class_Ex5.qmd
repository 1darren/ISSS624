---
title: "In-class Exercise 5: Spatial Econometrics"
date: "16 Dec 2023"
date-modified: "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning: false
editor: source
---

::: {.callout-note collapse="true"}
### Hidden: In-Class Lecture notes

## In-Class Lecture Notes

"In real world, there is no concept of equality." -- Prof Kam

```         

### Take-home Exercise notes:
- Econometrics as "applied regression model";
  - A continuation of spatial weights + regression model 
  - Typically, 3-4 terms 
  
- Quantitative Analysis of economic phenomenon, based on development of theory & observation
  - Statistics applied to econometrics
- Spatial Econometrics: study of economic phenomena with spatial dependence; economic activity is related to location of factors of production.

- In-Class Exercise:
    - Data Preparation (skipped): focus on part 2, 
    - Model Calibration


 
```
:::

# 5. In-Class Ex 5

## 5.1 Import Packages

- First pre-load spflow from github directly:
```{r}
#| eval: false
devtools::install_github("LukeCe/spflow")
```

-   `httr` HTML features, communicate with webserver

-   `tidyverse` Data science work

-   `tmap` Visual plotting

-   `sf` Geospatial work

-   `spflow` Spatial Econometric Interaction Models / Sum Product
    - useful to perform SpaEcoIntMod without having to write low-level code


-   `Matrix` optimised package for running computations on large Matrix

```{r}
pacman::p_load(tidyverse, sf, httr, tmap, spflow, tmap,
               spdep, sp, Matrix, reshape2, knitr)
```

## 4.2 Loading data

-   Spflow requires:
  - Spatial weights
  - tibble df of OD Flows
  - tibble df of explanatory variables
      - by right, don't need to attach to origin or destination; 
      - within the 9 models, it will identify the variables as "Origin" or "Destination
        
        
- load mpsz, busstop data
  - use st_intersects to identify subzone with bus stops
  - filter out mpsz with 0 busstops
  
  
```{r}

mpsz <- st_read(dsn = "data/geospatial", 
                 layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
# st_crs(mpsz)

busstop <- st_read(dsn = "data/geospatial", 
                 layer = "BusStop") %>%
  st_transform(crs = 3414)


mpsz$`BUSSTOP_COUNT` <- lengths(
  st_intersects(
    mpsz, busstop))

mpsz_busstop <- mpsz %>%
  filter(BUSSTOP_COUNT > 0)
mpsz_busstop
```

## create spatial weights

- "tricky way to make computation effective"
    - derive centroids in one stpe
    - create `mpsz_nb` with 3 different nb matrix techniques (contiguity, distance knn)
- prof Kam has already shifted one busstop to avoid 

```{r}
#| code-fold: true
#| code-summary: "show code"

centroids <- suppressWarnings({
  st_point_on_surface(st_geometry(mpsz_busstop))
})
mpsz_nb <- list(
  "by_contiguity" = poly2nb(mpsz_busstop), 
  "by_distance" = dnearneigh(centroids, d1=0, d2=5000),
  "by_knn" = knn2nb(knearneigh(centroids, 3))
)
mpsz_nb

```
- note that `$by_contiguity` has no orphans;
- note that `$by_distance` has one region, 313, with no neighbours;


- import schoolcs.scv
- rename cols to LATITUDE LONGITUE
- retian only potla_code, school_name, lat, long

- when feeding arguments, always specify LONGITUDE then LATITUDE because of cartesian coordinates convention (x, y) 
- specify initial coords of initial untransformed data (WGS84, crs4326)

```{r}
#| code-fold: true
#| code-summary: "show code"

```

-   `rds` saves the R object, preserving the classes;

    -   `mpsz` was `sf` `tibble` dataframe in Hands-on Ex03; here it is reproduced in the same class from previously loaded

    -   If we instead exported as shapefile, many details will be lost

    -   Alternatively, we could perform st_read from previous

```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false

```


- Point-in-polygon count
    - polygon & points should be in same projection, e.g. 3414
- Why use `st_intersects()` over `st_within()`?
    - can also; but intersection has same output 
    - use of `lengths()` to count number of schools within mpsz
    
    
- `business` dataset : SME businesses


```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false

```


- `business` dataset : SME businesses


```{r}
#| code-fold: true
#| code-summary: "show code"

#| eval: false

```

- trick: plot base map of polygon map, before plotting dot map
    - this will place points, lines over polygn
- use `tmap_options(check.and.fix = True)` to close/reunite polygon
    - eg geometry not closed, from busstop
    
- business, school location are attractiveness, AT DESTINATOIN
    - trick: left join destin_sz = subzone c
    - if join on origin, will be propulsive
    
    
- for Poisson regression, we need to check for 0, coerce to 0.99
    - just a small number below 1


# IN-Class ex 4 


```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
pacman::p_load(tmap, sf, DT, stplanr,
               performance,
               ggpubr, tidyverse)
```

-
```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
flow_data <- read_rds("data/rds/flow_data_tidy.rds")

# note that RETAIL_COUNT is mislabelled, should really be BUSINESS_COUNT
glimpse(flow_data)
```

- steps: remove intrazonal trips
    - by definition, all attractiveness/propulsiveness within the zone is the same; not useful
    - we want to understand what makes people travel between zones
    
    
- write to RDS after data cleaning, to avoid re-running when fitting SIM model
    - also, clear environment of objects, to avoid storage
    - for rigour, clear cache regularly 
    
    
- 4 models under gravity
    - unconstrained
    - origin-constrained  : only have attractiveness factors (eg school, retail)
    - destination-constrained
    - doubly constrained
- previously, population: not valuable 
- distance still retained, as impedance;
- for origin/destination constrained, you don't need intercept -- so, he has formula = ... -1
    - na.action = na.exclude: failsafe drop NA 
    
- what we're looking at is log(SCHOOL_COUNT), log(RETAIL_COUNT), log(DIST)
    - ideally, low signif codes => significant factors
    - we also want to interpret the parameters correctly
        - log(DIST) should be negative -> by right, always inverse distance
        - attractiveness params should be positive, propulsiveness should be negative
        - contrast: CRIME RATE should be negative (we want lower crime rate)
        
        
- GLM does not provide r-squared
- we define a function, `CalcRSquared` to calculate R^2 for goodness of fit
    - base R has correlation function `cor()`
    - we square -- positive/negative correlation is possible
    
- output of GLM, `orcSIM_Poisson`, is a model object / list of 30 objects
    - some objects are:
        - `coefficients` for column/variables
        - `residuals`` errors for each interzonal flow <- can be joined to inter_zonal flow
        - `fitted.values` expected_Y based on model
        
- can be extracted using as_dataframe() with `orcSIM_Poisson$residuals`

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "show code"
CalcRSquared <- function(observed, estimated){
  r <- cor(observed, estimated)
  R2 <- r^2
  R2
}

# CalcRSquared( $trips, $fitted.values)


# performance_rmse(orcSIM_Poisson, normalized = False)
# get raw RMSE instead of normalised value 
```

- for doubly-constrained, "don't need to worry about intercept" don't need to -1
- use chap16#model-compariosn 
    - lowest RMSE si morebest
- multiplot if RMSE is large, scatter is larger
    - may want to drop that one massive outlier   




