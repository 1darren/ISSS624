---
title: "Take-home Exercise 2"
editor: source
---

# 0. Goals & Objectives.

Our goal is to conduct a case study to demonstrate the potential value of Geospatial Data Science & Analysis, by integrating publicly available data from multiple sources to build a spatial interaction models, to determine factors affecting urban mobility patterns of public bus transit.

Recentdeployments of massively pervasive computing technologies such as in-vehicle GPS and SMART cards by public transport provide plenty of data for tracking movement patterns through space and time, but the explosive growth of data has outstripped public services' ability to utilise, transform, and understand the data.

More detail about the task from: <https://isss624-ay2023-24nov.netlify.app/take-home_ex02>

Modifible Areal Unit Problem (MAUP): - MPSZ is too coarse, too huge a subzone area; people may live only in a corner of the subzone - Planning subzones too large, so we use analytical hexagon

"Map is not interesting, pattern revealed by and factors affecting the map is interesting. Can we explain this by building a spatial model?" - Building a model to explain flows; `Spatial Interaction Model`

GLM: Generalised Linear-Regression Model (over linear model):

-   Dwelling Units as proxy for population;
-   Can compare HDB-only VS dwelling units vs room-flat vs 1/2/3/ room flat unit
-   POI: points of interest name & type

::: callout-important
## Important Note

Due to the nature of EDA and Data Analysis, parts of this page have been Collapsed or placed behind tabs, to avoid excessive scrolling.

For easier reading, this study is also presented in point-form.
:::

## 0.1 Dataset used

### 0.1.1 Aspatial Dataset

+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+
| Dataset, Purpose & Source:                                                                                             | Key columns                                                                      |
+========================================================================================================================+==================================================================================+
| `hdb.csv` : HDB Property information data with geocoding                                                               | -   `lat`, `long`: coordinates \|                                                |
|                                                                                                                        | -   `max_floors`, `total_dwelling_units` : idea of how many units each HDB holds |
| *Via [data.gov](https://beta.data.gov.sg/collections/150/view)*                                                        |                                                                                  |
+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+
| `origin_destination_bus_202310` : Volume of bus passenger trips, by origin/destination, data prepared for 2023 October | -   `ORIGIN_PT_code`, `DESTINATION_PT_code`: O/D information on bus trip         |
|                                                                                                                        | -   `TIME_PER_HOUR`, `DAY_TYPE`: Time/Date data on when the trips were taken     |
| *Via [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html)*                                             | -   `TOTAL_TRIPS`: Bus trip passenger volume                                     |
+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+

### 0.1.2 Geospatial Dataset

+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+
| Filename, Purpose & Source:                                                                                            | Key columns                                                                      |
+========================================================================================================================+==================================================================================+
| `hdb.csv` : HDB Property information data with geocoding                                                               | -   `lat`, `long`: coordinates \|                                                |
|                                                                                                                        | -   `max_floors`, `total_dwelling_units` : idea of how many units each HDB holds |
| *Via [data.gov](https://beta.data.gov.sg/collections/150/view)*                                                        |                                                                                  |
+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+
| `origin_destination_bus_202310` : Volume of bus passenger trips, by origin/destination, data prepared for 2023 October | -   `ORIGIN_PT_code`, `DESTINATION_PT_code`: O/D information on bus trip         |
|                                                                                                                        | -   `TIME_PER_HOUR`, `DAY_TYPE`: Time/Date data on when the trips were taken     |
| *Via [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html)*                                             | -   `TOTAL_TRIPS`: Bus trip passenger volume                                     |
+------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+

: Sample grid table. \|

# 1. Geospatial Data Wrangling

This study was performed in R, written in R Studio, and published using Quarto.

## 1.1 Import Packages

This function calls `pacman` to load sf, tidyverse, tmap, knitr packages;

-   `tmap` : For thematic mapping; powerful mapping package;
-   `sf` : for geospatial data handling, but also geoprocessing: buffer, point-in-polygon count, etc;
-   `sp` : for `spDists()` at high speed
-   `reshape2` : for `melt()` instead of `pivot_longer()`
-   `sfdep` : useful functions for creating weight matrix, LISA calculations etc;
-   `tidyverse` : for non-spatial data handling; commonly used R package and contains `dplyr` for dataframe manipulation and `ggplot` for data visualization;
-   `DT`: for displaying datatables;
-   `leaflet`: for custom layer controls over `tmap` visualisations.
-   `stplanar`: for creating desire lines to visualize O/D flows

```{r}
pacman::p_load(tmap, sf, sfdep, tidyverse, DT, leaflet, stplanr, sp, reshape2, wdpar)

devtools::install_github("thomasp85/patchwork")
library(patchwork)
```

## 1.2 Import Geospatial Data

### 1.2.1 `raw_bus_stop_sf`: Load Geospatial Bus Stop Data

-   First, we load `BusStop` shapefile data from [LTA Datamall](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html);
-   `st_read()` is used to import the ESRI Shapefile data into an `sf` dataframe.
    -   From previous take-home exercise, we know BusStop has the incorrect CRS (coordinate reference system), as EPSG 9001 instead of 3414, so we use `st_set_crs()` to correct this
    -   We use `head()` to preview the first 6 rows

```{r}
#| code-fold: true
#| code-summary: "show code"
raw_bus_stop_sf <- st_read(dsn = "data/geospatial", 
                 layer = "BusStop") %>%
  st_set_crs(3414)
head(raw_bus_stop_sf)
```

-   We check the coordinate reference system with `st_crs()`; and see that it is now indeed correctly set to 3414:

::: {.callout-warning collapse="true"}
## EXPAND To See: Full `st_crs`Readout

```{r} 
#| code-fold: true 
#| code-summary: "show code"  
st_crs(raw_bus_stop_sf)
```
:::

- We use `qtm()` to perform a quick visualization of the various bus stops:
```{r}
#| code-fold: true
#| code-summary: "show code"

tmap_mode("plot")
qtm(raw_bus_stop_sf)

```



### 1.2.2 `mpsz_sf`:  Visualizing Singapore's Master Plan 2019 Subzone  Boundaries

-   We now load Master Plan 2019 Subzone Boundary

-   Next, we load `MPSZ-2019` shapefile data from [Data.gov.sg](https://beta.data.gov.sg/collections/1749/view), comprising *Master Plan 2019 Subzone Boundary (No Sea)* data ;
-   `st_read()` is used to import the ESRI Shapefile data into an `sf` dataframe;
    - We use `st_crs()` to check the Coordinate Reference System (CRS);

```{r}
#| code-fold: true
#| code-summary: "show code"

mpsz_sf <- st_read(dsn = "data/geospatial", 
                 layer = "MPSZ-2019") 
st_crs(mpsz_sf)
```

- We see that `MPSZ-2019` is set to WGS 84/EPSG 4326 projection, which is inconsistent with the rest of our dataset;
- Thus, we use `st_transform()` to reproject the data to SVY21/EPSG 3414 Coordinate Reference System (CRS) to ensure consistent distance calculation:

```{r}
#| code-fold: true
#| code-summary: "show code"

mpsz_sf <- mpsz_sf %>%
  st_transform(crs=3414)
st_crs(mpsz_sf)
```
- Now, let's visualize the bus stop within the `mpsz` subzone boundaries;
-   We set `tmap_mode("plot")` to allow us to scroll;
-   We use `tm_shape() + tm_polygons()` to map a base layer of the `mpsz` boundaries;
    -   On top of which, we layer `tm_shape() + tm_dots()` to show the bus stops.

```{r}
#| code-fold: true
#| code-summary: "show code"
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz_sf) +
  tm_polygons() + 
  tm_shape(raw_bus_stop_sf) + 
  tm_dots()

```

-   We note there are a number of bus stops outside Singapore's boundaries; Specifically, three bus stops in a cluster just outside the Causeway, and one further North.
-   We perform several steps to isolate & check the data;
    -   we use `st_filter()` to find bus stops within Singapore's Administrative National Boundaries, and create `sg_bus_stop_sf` for future use.
    -   to check what bus stops have been dropped, we use `anti_join()` to compare `raw_bus_stop_sf` with `sg_bus_stop_sf`. We use `st_drop_geometry` on both `sf` dataframes to only compare the non-geometry columns.

```{r}
#| code-fold: true
#| code-summary: "show code"
sg_bus_stop_sf <- st_filter(raw_bus_stop_sf, mpsz_sf)
anti_join(st_drop_geometry(raw_bus_stop_sf), st_drop_geometry(sg_bus_stop_sf))

```

-   We see there are in fact 5 bus stops outside of Singapore (including the defunct [Kotaraya II Terminal](https://landtransportguru.net/kotaraya-ii-bus-terminal/)) that have been removed, which means our data cleaning was correct.

## 1.3 Geospatial Data Cleaning

### 1.3.1 Removing Duplicate Bus Stops

-   From [Take-home Exercise 1](Take-home_Ex01/take_home_ex_01.html), we know that there are a number of repeated bus stops. We repeat some steps;
-   We use `length()` to find the total number of raw values in the `$BUS_STOP_N` column of `sg_bus_stop_sf;`
    -   We then compare this to `length(unique())` to find the unique values;
-   And, indeed, we find there are 16 bus stops that are repeated;

```{r}
#| 
cat("\nResults before removing duplicates: \n=======================================================\n")
cat("Total number of rows in sg_bus_stop_sf\t\t: ", paste0(length(sg_bus_stop_sf$BUS_STOP_N)))
cat("\nTotal unique bus stop IDs in sg_bus_stop_sf\t: ", paste0(length(unique(sg_bus_stop_sf$BUS_STOP_N))))
cat("\nRepeated bus stops\t\t\t\t:   ", paste0(length(sg_bus_stop_sf$BUS_STOP_N) - length(unique(sg_bus_stop_sf$BUS_STOP_N))))

```

-   It appears there are 16 datapoints that are specifically repeated; let's remove them by deleting the duplicated rows:
    -   we use `duplicated()` to identify rows with repeated values of `$BUS_STOP_N`; duplicated rows will return `TRUE` while all other rows will return `FALSE`
    -   We use `!` to invert the values, so only the unduplicated rows will return `TRUE`.
    -   We then use square brackets `[]` to index `sg_bus_stop_sf` based on the rows, and return only the unduplicated rows;
    -   We then assign the output using `<-` into `bus_stop_sf`, for use.

```{r}
#| code-fold: true
#| code-summary: "show code"
bus_stop_sf <- sg_bus_stop_sf[!duplicated(sg_bus_stop_sf$BUS_STOP_N), ]
head(bus_stop_sf)

cat("\nResults after removing duplicates: \n=======================================================\n")
cat("Total number of rows in bus_stop_sf\t\t: ", paste0(length(bus_stop_sf$BUS_STOP_N)))
cat("\nTotal unique bus stop IDs in bus_stop_sf\t: ", paste0(length(unique(bus_stop_sf$BUS_STOP_N))))
cat("\nRepeated bus stops\t\t\t\t:   ", paste0(length(bus_stop_sf$BUS_STOP_N) - length(unique(bus_stop_sf$BUS_STOP_N))))
```

-   We can do a quick check to visualize these;
    - We use `tmap_mode("view")` to allow us to scroll around and check that the bus stops fall within Singapore's national boundaries, and set zoom limits to focus the attention
    - We combine `tm_shape()` and `tm_polygons()` to map the master plan subzones in grey;
    - We combine `tm_shape()` and `tm_dots()` to map locations of bus stops; for visual distinction with the grey zones, we use the "Spectral" palette

```{r}
#| code-fold: true
#| code-summary: "show code"
tmap_mode("view")
tm_shape(mpsz_sf) +
  tm_polygons() + 
  tm_shape(bus_stop_sf) + 
  tm_dots(col = "BUS_STOP_N", palette = "Spectral", legend.show = FALSE) + 
  tm_view(set.zoom.limits = c(11, 13))
tmap_mode("plot")
```

-   Now, we can start preparing the hexagon map. 

## 1.4 Generating Hexagon Maps

- We generate the hexagon map in three steps:
1. We use `st_make_grid()` with `square = FALSE` to create the hexagon layer as defined in the study, which we name `raw_hex_grid`;
    -   We pass `cellsize = 750` to create the hexagons of necessary size. Prof Kam defined the apothem as 375m, as the [Traffic Analysis Zone](https://en.wikipedia.org/wiki/Traffic_analysis_zone) is typically 750m in size.
    -   I used `units::as_units` to pass 750 metres into the argument. I am still uncertain whether a length of 750m needs to be reprojected, or whether we need to do any further transformation.
    -   We use `st_transform()` just in case we need to reproject the coordinate system, just in case.
2.   We use `st_sf()` to convert `raw_hex_grid` into an `sf` dataframe for further manipulation later;
    - However, trying to visualize this right now just gives us a map full of hexagons, so need to eliminate the empty hexagons;
    - We use `mutate()` to create a new column, `$n_bus_stops` that counts the number of bus stops in each hexagon using `lengths(st_intersects())`
        - `st_intersects()` gives us a list of bus stops in each hexagon, so we use `lengths()` to count the number
3.   We create our final `sf` dataframe, `hexagon_sf` in two steps;
    - First, we use `filter()` to select only hexagons with nonzero number of bus stops;
    - Then,  `mutate()` is used here to create a `grid_id` column, labelling only the hexagons with nonzero bus stops. 
    
- Finally, we perform a quick plot to confirm that every bus stop is inside a hexagon;
    - Using `hexagon_sf` as our base layer, we use `tmap_shape()` and `tm_polygons()` to visualizes our hexes. We pass `palette = "Spectral"` for visual distinguishment against the black dots of the bus stops.
    - We use `tmap_shape()` and `tm_dots()` to visualize our bus stop as black dots

```{r}
#| code-fold: true
#| code-summary: "show code"

# STEP 1 - Create hexagon map 
raw_hex_grid <- st_make_grid(bus_stop_sf, cellsize = units::as_units(375, "m"), what = "polygons", square = FALSE) %>%
  st_transform(crs = 3414)

# STEP 2 - Convert to sf object and count the number of bus stops inside;
raw_hex_grid <- st_sf(raw_hex_grid) %>%
  mutate(n_bus_stops = lengths(st_intersects(raw_hex_grid, sg_bus_stop_sf))) 

# Count number of points in each grid, code snippet referenced from: 
# https://gis.stackexchange.com/questions/323698/counting-points-in-polygons-with-sf-package-of-r


# STEP 3 - Filter for nonempty hexes and label:

hexagon_sf <- filter(raw_hex_grid, n_bus_stops > 0) 
hexagon_sf <- hexagon_sf %>%
  mutate(grid_id = 1:nrow(hexagon_sf)) %>%
  select(grid_id, raw_hex_grid, n_bus_stops)

tmap_mode("plot")
tm_shape(hexagon_sf) +
  tm_polygons(col = "grid_id", palette = "Spectral", legend.show = FALSE) + 
  tm_shape(bus_stop_sf) + 
  tm_dots()
tmap_mode("plot")
```

- We can visually confirm that every black dot is within a hexagon.
- We re-use a bit of code from Take-Home Exercise 1 to plot our analytical hexagons on a map of Singapore and visualize the number of bus stops in each hexagon:

```{r}
#| code-fold: true
#| code-summary: "show code"
tmap_mode("view")
tm_basemap(providers$OneMapSG.Grey) + 
  tm_shape(hexagon_sf) +
  tm_fill(
    col = "n_bus_stops",
    palette = "-plasma",
    style = "cont",
    
    breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),
    title = "Number of bus_stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of Bus Stops: " = "n_bus_stops"
    ),
    popup.format = list(
      n_bus_stops = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)  + 
  tm_view(set.zoom.limits = c(11, 13))
tmap_mode("plot")
```

-   We perform some simple stats to count the total number of filtered hexagons, and to see the maximum number of bus stops in a hexagon.
    - Unlike Take-Home Exercise 1, the number of hexagons have decreased, and the maximum number of bus stops per hexagon is lower.

```{r}
#| code-fold: true
#| code-summary: "show code"


# NB: Code reused from my own take-home exercise 1
cat(paste("Total number of raw hexagons is\t\t\t: ", nrow(raw_hex_grid), "\n"))
cat(paste("Total number of hexagons (n_bus_stop > 1) is\t: ", nrow(hexagon_sf)), "\n")

cat("\nPrinting map_hexagon_sf:\n >> ")
hexagon_sf[hexagon_sf$n_bus_stops > 5, ]
```

-   For the next step, we'll need to manage the aspatial bus trips dataset, which is what we'll work on now.

## 1.5 Aspatial Data Wrangling: Bus trip dataset

### 1.5.1 Import Bus O/D Dataset

-   For our purposes, we will focus only on 2023-October *Passenger Volume by Origin Destination Bus Stops*, downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html);

-   We use `read_csv()` to load the data from the .csv file;
-   We use `select()` with a `-` sign to remove two columns redundant for our analysis:
    -   `$PT_TYPE` column indicates the type of public transport, however, every value is "BUS"
    -   `$YEAR_MONTH` column similarly has "2023-10" for every value, which we are aware of
    -   With this in mind, we drop these two columns to save space.
-   Finally, we use `mutate_at()` to convert two columns (`$ORIGIN_PT_CODE` and `$DESTINATION_PT_CODE`)from character to factor, for easier analysis.
- We use `str()` to check the columns, datatypes, and number of rows:

```{r}
#| code-fold: true
#| code-summary: "show code"
odbus_2310 <- read_csv("data/aspatial/origin_destination_bus_202310.csv") %>%
  select( -PT_TYPE, -YEAR_MONTH) %>%
  mutate_at(c("ORIGIN_PT_CODE", "DESTINATION_PT_CODE"), as.factor)

str(odbus_2310)
```

-   This is a huge `tibble` dataframe with over 5 million rows, so we will filter this now by peaks;
- For this study, we focus on Weekday afternoon peak

### 1.5.2 Filter For Peaks -- Weekday Afternoon

-   We now perform a multi-step filter process;
    1.  We combine `mutate()` with `case_when()` to create a new column, `$PEAK`, based on the study criteria:
        a.  We set the value to "WEEKDAY_AFTERNOON_PEAK" if `$DAY_TYPE` is "WEEKDAY" and bus tap-on time (e.g. `$TIME_PER_HOUR`) is between 5 pm and 8pm, inclusive;
            - Note that we convert the values for `$TIME_PER_HOUR` to 24-hour clock, e.g. "5pm" is "17" hundred hours, "8pm" is "20" hundred hours.
        b.  For all remaining values, we assign an "Unknown" value.
    2.  We then use `filter()` to eliminate those with "Unknown" `$PEAK` values, i.e. rows outside the period of interest for the study
    3.  We use `group_by()` to group the values by `$ORIGIN_PT_CODE` and `$DESTINATION_PT_CODE`, and use `summarise()` to aggregate the sum of `$TOTAL_TRIPS` as a new column, `$TRIPS`.
    4.  We use `write_rds()` to save the output dataframe, `odbus_filtered`, as an RDS object for future reference/load.

```{r}

odbus_filtered <- odbus_2310 %>%
  mutate(PEAK = case_when(
    DAY_TYPE == "WEEKDAY" & TIME_PER_HOUR >= 17 &  TIME_PER_HOUR <= 20 ~ "WEEKDAY_AFTERNOON_PEAK",
    TRUE ~ "Unknown"
  )) %>%
  filter(
    case_when(
      PEAK == "Unknown" ~ FALSE,
      TRUE ~ TRUE
    )) %>%
  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))


write_rds(odbus_filtered, "data/rds/odbus_filtered_weekday.rds")
head(odbus_filtered)
```

## 1.6 Combine Bus Trip Data With `hexagon_sf` Dataframe

-   For our study purposes, we need to have the number of bus trips originating from each hexagon. In order to achieve this, we must combine our three current dataframes:
    -   `hexagon_sf`, an `sf` dataframe with `$grid_id` column (primary key) and the specific polygon geometry of each hexagon;
    -   `bus_stop_sf`, an `sf` dataframe with the `$BUS_STOP_N` (primary key) and the point geometry of each bus stop;
    -   `odbus_filtered`, a `tibble` dataframe with the `$ORIGIN_PT_CODE` (primary key) column and the trip details for each of the four peak periods of interest.

### 1.6.1 `bus_stop_hexgrid_id`: Identify Hexagon `grid_id` For Each Bus Stop

-   First, we combine `hexagon_sf` with `sg_bus_stop_sf` ;
    -   We use `st_intersection` to combine the dataframes such that each row of `sg_bus_stop_sf` has an associated `grid_id`;
    -   We use `select()` to filter the resultant `bus_stop_hexgrid_id` dataframe to only `$grid_id` and `$BUS_STOP_N` columns, and use `st_drop_geometry()` to convert into a simple dataframe with just two columns:

```{r}
#| code-fold: true
#| code-summary: "show code"

bus_stop_hexgrid_id <- st_intersection(bus_stop_sf, hexagon_sf) %>%
  select(BUS_STOP_N, grid_id) %>%
  st_drop_geometry()

cat("\nNumber of bus stops\t:", length(unique(bus_stop_hexgrid_id$BUS_STOP_N)))
cat("\nNumber of hexgrids\t:", length(unique(bus_stop_hexgrid_id$grid_id)))

head(bus_stop_hexgrid_id)
```

- Eagle-eyed readers may notice that **BUS_STOP_N #25059** is in both `$grid_id` 1 & 2; 
- Let's check if there's any other duplicates:

```{r}
#| code-fold: true
#| code-summary: "show code"

bus_stop_hexgrid_id$BUS_STOP_N[duplicated(bus_stop_hexgrid_id$BUS_STOP_N)]
```
- Only **BUS_STOP_N #25059** is duplicated; let's see why this is:

```{r}
#| code-fold: true
#| code-summary: "show code"

tmap_mode("view")
tm_shape(hexagon_sf[hexagon_sf$grid_id %in% c(1, 2),]) +
  tm_polygons(col = "grid_id", palette = "Spectral") + 
  tm_shape(bus_stop_sf[bus_stop_sf$BUS_STOP_N %in% c(25059),]) + 
  tm_dots()
tmap_mode("plot")
```

- It appears that **BUS_STOP_N #25059** is exactly on the boundary between the two hexagons. 
- Here we perform simple manual intervention data cleaning, declaring the bus stop is in `$grid_id` 2 by deleting the first row;
    - We use `subset()` to select values of `$grid_id` that are not equal to 1

```{r}
#| code-fold: true
#| code-summary: "show code"


bus_stop_hexgrid_id <- subset(bus_stop_hexgrid_id, grid_id != 1)

cat("\nNumber of bus stops\t:", length(unique(bus_stop_hexgrid_id$BUS_STOP_N)))
cat("\nNumber of hexgrids\t:", length(unique(bus_stop_hexgrid_id$grid_id)))



cat("\n\nPrinting rows with duplicated bus stop values\t:", bus_stop_hexgrid_id$BUS_STOP_N[duplicated(bus_stop_hexgrid_id$BUS_STOP_N)])
cat("\n\n(If empty, it worked!)")
```

- Now we append hexagon code onto `odbus_filtered`. We do this in two steps;
- First, we use `left_join()` to add the hexagon `$grid_id` by `BUS_STOP_N` number;
    - We use `rename()` to rename columns, and specify the origin bus stop and origin hex grid id as `ORIGIN_BS` and `ORIGIN_HEX` respectively;
    - We create a `duplicate` tibble data.frame to check for duplicate results, and luckily we see an empty tibble


```{r}
#| code-fold: true
#| code-summary: "show code"

od_data <- left_join(odbus_filtered , bus_stop_hexgrid_id,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEX = grid_id)
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate

# od_data[!complete.cases(od_data), ]
# 
# bus_stop_hexgrid_id[] 
# hexagon_sf[hexagon_sf$grid_id %in% c(1, 2),]

# bus_stop_hexgrid_id[bus_stop_hexgrid_id$BUS_STOP_N %in% c(03361),]

# 
# raw_bus_stop_sf[raw_bus_stop_sf$BUS_STOP_N %in% c(03361, 03549, 03579, 59009),]
```

- Now we repeat the step, appending the destination hex ID




```{r}
#| code-fold: true
#| code-summary: "show code"

od_data <- left_join(od_data , bus_stop_hexgrid_id,
            by = c("DESTINATION_PT_CODE" = "BUS_STOP_N")) %>%
  rename(DESTIN_BS = DESTINATION_PT_CODE,
         DESTIN_HEX = grid_id)
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
duplicate

# od_data[!complete.cases(od_data), ]
```

- Once again, we have an empty tibble. 
- We finally create the final version of our flow dataset.
    - Just to be safe, we perform a step to remove duplicates using `unique()`
    - `drop_na()` removes bus stops for which we have no info. It turns out there are bus stop numbers outside our bus stop dataset, like 03361, 03549, 03579, 59009;
        - Some of these may be new bus stops, like [03361](https://www.transitlink.com.sg/eservice/eguide/bscode_idx.php?bs_code=03361), Gardens by the Bay Stn Exit 2, and [03549](https://www.transitlink.com.sg/eservice/eguide/bscode_idx.php?bs_code=03549)
    - We use `group_by()` to combine rows with the same `$ORIGIN_HEX` and `$DESTIN_HEX`, and aggregate the number of trips with `summarise()`


```{r}
#| code-fold: true
#| code-summary: "show code"


od_data <- od_data %>%
  unique() %>%
  drop_na() %>%
  group_by(ORIGIN_HEX, DESTIN_HEX) %>%
  summarise(SUM_TRIPS = sum(TRIPS))
head(od_data)
```

- Now we write the output to RDS 

```{r}
#| code-fold: true
#| code-summary: "show code"


write_rds(od_data, "data/rds/od_data.rds")
od_data <- read_rds("data/rds/od_data.rds")
```





- Remove intrazonal flows

```{r}
#| code-fold: true
#| code-summary: "show code"

od_data1 <- od_data[od_data$ORIGIN_HEX!=od_data$DESTIN_HEX,]
```


- Create desire lines

```{r}
#| code-fold: true
#| code-summary: "show code"

flowLine <- od2line(flow = od_data1, 
                    zones = hexagon_sf,
                    zone_code = "grid_id")
summary(od_data1$SUM_TRIPS)
```

- Quick exploration: most values are below 500
```{r}
#| code-fold: true
#| code-summary: "show code"

lplot <- ggplot(data = flowLine, aes(x=SUM_TRIPS, y=ORIGIN_HEX)) +
  geom_point()  +
  labs(title = "Histogram with Different Fill Colors",
       x = "Value",
       y = "Frequency") + 
  geom_vline(xintercept = 1000, colour="red")
rplot1 <- ggplot(data = flowLine, 
                aes(x=SUM_TRIPS)) +
  geom_histogram(breaks=seq(0, 20000, by = 1000)) + 
  geom_vline(xintercept = 1000, colour="red")
rplot2 <- ggplot(data = flowLine, 
                aes(x=SUM_TRIPS)) +
  geom_histogram(breaks=seq(0, 2000, by = 500)) + 
  geom_vline(xintercept = 1000, colour="red")

lplot / (rplot1 + rplot2)
```


```{r}

custom_palette <- c('#fee090','#d73027','#72001a', '#313695')
tmap_mode("plot")
tm_shape(hexagon_sf) +
  tm_polygons() +
flowLine %>%  
  filter(SUM_TRIPS >= 1000) %>%  
  tm_shape() +
  tm_lines(col = "SUM_TRIPS",
           lwd = "SUM_TRIPS",
           palette = custom_palette,
           style = "fixed",
           breaks = c(1000, 2000, 4000, 8000, 100000),
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.8)
```
- Plotting trips over 10,000:
    - 150 trips over 10,000
    - 20 trips over 20,000

```{r}
flowLine[flowLine$SUM_TRIPS>=20000,]
```

```{r}

custom_palette <- c('#fee090','#fee090','#d73027','#d73027','#72001a', '#313695')
tmap_mode("plot")
tm_shape(hexagon_sf) +
  tm_polygons() +
flowLine %>%  
  filter(SUM_TRIPS >= 10000) %>%  
  tm_shape() +
  tm_lines(col = "SUM_TRIPS",
           lwd = "SUM_TRIPS",
           palette = custom_palette,
           style = "jenks",,
           scale = c(1, 2, 4, 8, 10, 14),
           n = 6,
           alpha = 0.8)
```


```{r}
#| code-fold: true
#| code-summary: "show code"


od_data1_origin <- od_data1 %>%
  group_by(ORIGIN_HEX) %>%
  summarise(SUM_ORIG_TRIPS = sum(SUM_TRIPS))



orig_hexagon_sf <- left_join(hexagon_sf, od_data1_origin, 
            by = c("grid_id" = "ORIGIN_HEX")) %>%
  select(grid_id, 
         SUM_ORIG_TRIPS, raw_hex_grid) %>%
  drop_na() 

ggplot(orig_hexagon_sf, aes(x = grid_id , y = SUM_ORIG_TRIPS)) +
  geom_boxplot(fill = "lightblue", color = "black", outlier.shape = 16, outlier.colour = "red") +
  geom_point(position = position_jitter(width = 0.2), color = "red", size = .5) +
  scale_y_log10() +
  labs(title = "Boxplot with Outliers Highlighted",
       x = "Category",
       y = "Value")



```

- find top 10% of tirps by origin hexes origin

```{r}
#| code-fold: true
#| code-summary: "show code"
origin_threshold <- quantile(orig_hexagon_sf$SUM_ORIG_TRIPS,  0.99) #237114
orig_trips_q90   <- quantile(orig_hexagon_sf$SUM_ORIG_TRIPS,  0.9) #237114
orig_trips_q99   <- quantile(orig_hexagon_sf$SUM_ORIG_TRIPS,  0.99) #237114
orig_trips_q999  <- quantile(orig_hexagon_sf$SUM_ORIG_TRIPS,  0.999) #237114
custom_origin_breaks <- c(0, orig_trips_q90, orig_trips_q99, orig_trips_q999, Inf)


# orig_hexagon_sf[orig_hexagon_sf$SUM_ORIG_TRIPS>500000,]


# custom_origin_breaks

# filter(orig_hexagon_sf, SUM_ORIG_TRIPS >= origin_threshold) 


tmap_mode("plot")
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(orig_hexagon_sf) +
  tm_polygons(col="SUM_ORIG_TRIPS", palette="YlGnBu", style = "fixed", breaks = custom_origin_breaks)

```

```{r}
#| code-fold: true
#| code-summary: "show code"

tmap_mode("plot")
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(filter(orig_hexagon_sf, SUM_ORIG_TRIPS >= 398408.9) ) +
  tm_polygons(col="SUM_ORIG_TRIPS", palette="-plasma") + 
flowLine %>%  
  filter(ORIGIN_HEX %in% c(279, 771, 2004)) %>%  
  tm_shape() +
  tm_lines(col = "SUM_TRIPS",
           lwd = "SUM_TRIPS",
           palette = custom_palette,
           style = "quantile",
           scale = c(1, 2, 4, 8, 10, 14),
           n = 6,
           alpha = 0.8)
# tm_basemap(providers$OneMapSG.Grey) + 
#   tm_shape(hexagon_sf) +
#   tm_fill(
#     col = "n_bus_stops",
#     palette = "-plasma",
#     style = "cont",
#     
#     breaks = c(0, 1, 2

```

- plot top 10 % of hexes by destination

```{r}
#| code-fold: true
#| code-summary: "show code"
od_data1_destin <- od_data1 %>%
  group_by(DESTIN_HEX) %>%
  summarise(SUM_DEST_TRIPS = sum(SUM_TRIPS))



dest_hexagon_sf <- left_join(hexagon_sf, od_data1_destin, 
            by = c("grid_id" = "DESTIN_HEX")) %>%
  select(grid_id, 
         SUM_DEST_TRIPS, raw_hex_grid) %>%
  drop_na() 


dest_trips_q90   <- quantile(dest_hexagon_sf$SUM_DEST_TRIPS,  0.9) #237114
dest_trips_q99   <- quantile(dest_hexagon_sf$SUM_DEST_TRIPS,  0.99) #237114
dest_trips_q999  <- quantile(dest_hexagon_sf$SUM_DEST_TRIPS,  0.999) #237114
custom_destin_breaks <- c(0, dest_trips_q90, dest_trips_q99, dest_trips_q999, Inf)

tmap_mode("plot")
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(dest_hexagon_sf) +
  tm_polygons(col="SUM_DEST_TRIPS", palette="YlOrRd", style = "fixed", breaks = custom_origin_breaks)
```

## 1.2 computing Distance matrix
- calculate & find top 10% of tirps by destin hexes 

```{r}
#| code-fold: true
#| code-summary: "show code"

hexagon_sf <- subset(hexagon_sf, grid_id != 1) # run without this line for 2172 hexagons
hexagon_sp <- as(hexagon_sf, "Spatial")
distance_matrix <- spDists(hexagon_sp, 
                longlat = FALSE)
head(distance_matrix, n=c(10, 10))
# dim(distance_matrix)
# hexagon_sf[hexagon_sf$grid_id == 2172,]
```

- melt distance matrix into distance pair

```{r}
#| code-fold: true
#| code-summary: "show code"
distPair <- melt(distance_matrix) %>%
  rename(dist = value
         , grid_id_from = Var1
         , grid_id_to = Var2)
head(distPair, 10)

# 1919	2172	
# subset(distPair, grid_id_from %in% c(1919, 2172) & grid_id_to  %in% c(1919, 2172))
# distPair[distPair$grid_id_from == 1919 & distPair$grid_id_to == 2172, ]
```



- melt distance matrix into distance pair

```{r}
#| code-fold: true
#| code-summary: "show code"
distPair %>%
  filter(dist > 0) %>%
  summary()
```
- Minimum distance 375
- We will arbirtraitly insert 50m into interzonal distance 

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
distPair %>%
  summary()
```
```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```


## 1.3 prepare flow data

```{r}
od_data

od_data$od_no_intra <- ifelse(
  od_data$ORIGIN_HEX == od_data$DESTIN_HEX, 
  0, od_data$SUM_TRIPS)
od_data$offset <- ifelse(
  od_data$ORIGIN_HEX == od_data$DESTIN_HEX, 
  0.000001, 1)

# od_data$ORIGIN_HEX <- as.factor(od_data$ORIGIN_HEX)
# od_data$DESTIN_HEX <- as.factor(od_data$DESTIN_HEX)
# 
od_data_distpair <- od_data %>%
  left_join (distPair,
             by = c("ORIGIN_HEX" = "grid_id_from",
                    "DESTIN_HEX" = "grid_id_to"))
od_data_distpair[od_data_distpair$od_no_intra == 0, ]
```

- however, we should filter this down to interzonal flow:
```{r}
inter_zonal_flow <- od_data_distpair %>%
  filter(od_no_intra > 0)
```

- visualize dependent variable
```{r}
ggplot(data = inter_zonal_flow,
       aes(x = SUM_TRIPS)) +
  geom_histogram()
```



- visualize dependent variable
```{r}
ggplot(data = inter_zonal_flow,
       aes(x = log(dist),
           y = log(SUM_TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

- check no zero values
```{r}
summary(inter_zonal_flow)
```



- unconstrained
```{r}
uncSIM <- glm(formula = SUM_TRIPS ~ 
                log(dist),
              family = poisson(link = "log"),
              data = od_data_distpair,
              na.action = na.exclude)
uncSIM

```





### 1.6.2 Identify Bus Trip Details For Each Hexagon `grid_id`

-   Here, we again use multiple steps to generate bus trip details for each hexagon `grid_id`;
    1.  We use `left_join()` to add the `grid_id` to each row of `odbus_filtered`, since each row has a unique single bus stop ID (i.e. `$BUS_STOP_N`);
    2.  We use `select()` to retain only the `grid_id` and the four peak-trips columns;
    3.  We combine `group_by()` and `summarise()` to aggregate the trips for each peak by `grid_id`.
-   Finally, we use `head()` to preview the `grid_trips_df` tibble dataframe.

```{r}
#| code-fold: true
#| code-summary: "show code"
colnames(odbus_filtered)

grid_trips_df <- left_join(odbus_filtered, bus_stop_hexgrid_id, 
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  select(grid_id, 
         TRIPS)  %>%
  group_by(grid_id) %>%
  summarise(
    TRIPS = sum(TRIPS)
    )
head(grid_trips_df)
```

### 1.6.3 Combine Bus Trip Details Back Into `hexagon_sf`

-   Finally, it's time to recombine bus trip data back into `hexagon_sf`;
    -   We use `left_join` on `$grid_id` to add trip data back into hexagon_sf;
    -   We add a failsafe `mutate()` to replace any "NA" values for the columns.

```{r}
#| code-fold: true
#| code-summary: "show code"
hexagon_sf <- left_join(hexagon_sf, grid_trips_df, 
            by = 'grid_id' ) %>%
  mutate(
    TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)
    )

head(hexagon_sf)

```

## 1.7 Exploratory Data Analysis Of Bus Trips, Across Peak Periods, By Hexagons

-   For `ggplot`, we need data in long format, so we can use `gather()` on `grid_trips_df` from Section 1.6.2 to pivot this;
-   We then pipe this into a `geom_boxplot()` for an exploratory look:

```{r}
#| code-fold: true
#| code-summary: "show code"


custom_breaks <- c(seq(0, 50000, by = 5000), 565000)

lplot <- ggplot(data = hexagon_sf, aes(x=TRIPS, y=grid_id)) +
  geom_point()  +
  labs(title = "Histogram with Different Fill Colors",
       x = "Value",
       y = "Frequency") + 
  geom_vline(xintercept = 20000, colour="red")
rplot <- ggplot(data = hexagon_sf[hexagon_sf$TRIPS <50001, ]
                , aes(x=TRIPS)) +
geom_histogram() + #breaks=seq(0, 50000, by = 5000) 
  geom_vline(xintercept = 20000, colour="red")

lplot / rplot

# str(hexagon_sf$TRIPS)


# gather(grid_trips_df, key = "Peak", value = "Trips", -grid_id) %>%
#   ggplot( aes(x=grid_id, y='TRIPS', fill=grid_id)) +
#   geom_boxplot() + 
#   ggtitle("Boxplot: Trips over peak periods, 2023-Oct data") +
#     xlab("") + 
#     theme(
#       legend.position="none"
#       ) +
#   coord_flip()
```

::: callout-tip
We also observe that number of trips for Weekday Morning & Weekday Afternoon seems to be larger than Weekend Morning and Weekend Evening peak trips. This is also confirmed by the figure in the next section.

This means that we will have to consider Weekday and Weekend peaks on different scales.
:::

-   This is an exceptionally ugly plot, but it shows an important point: there is some serious right skew in our dataset;
-   Clearly, there are some hexagons with exceptionally high trips compared to the rest of the hexagons But, could this be because some hexagons have up to 11 bus stops, while others have 1 or 2?
-   We do a quick scatter plot based on `$n_bus_stops` to verify this:

```{r}
#| code-fold: true
#| code-summary: "show code"
# hexagon_sf %>% 
#   st_drop_geometry() %>% 
#   pivot_longer(cols = starts_with("WEEK"),
#                names_to = "PEAK", values_to = "TRIPS") %>%
#   ggplot( aes(x=TRIPS, y=n_bus_stops, color=PEAK, shape=PEAK)) +
#   geom_point(size=2) +
#   ggtitle("Scatterplot: Trips over peak periods by number of bus stops per hexagon, 2023-Oct data") +
#     theme(legend.position=c(.85, .15),
#           legend.background = element_rect(fill = "transparent"),
#           legend.key.size = unit(0.5, "cm"),  
#           legend.text = element_text(size = 6),
#           legend.title = element_text(size = 8)
#     ) 
```

-   Surprising results from our plot! If we consider those with \> 100,000 trips as outliers, most of them come from hexagons with between 4-8 bus stops;
-   There is some correlation between number of bus stops and high numbers of trips, but a stronger factor is peak time; Weekday Morning peak trips, followed by Weekday Afternoon peak trips, contribute to the largest outliers.

::: callout-tip
I note that these visualizations only scrape the surface of understanding the data. However, this is not the focus of our study; we do these quick visualizations only to provide better context for our study.
:::

# 2. Preparing three propulsive and three attractiveness variables
## 2.1 Preparing Business:

- read in business values
- check st_crs: correct
```{r}
#| code-fold: true
#| code-summary: "show code"
business_sf <- st_read(dsn = "data/geospatial",
                      layer = "Business")
st_crs(business_sf)
```

- quick visualization
```{r}

tmap_mode("plot")
# tmap_options(check.and.fix = TRUE)
tm_shape(hexagon_sf) +
  tm_polygons() +
tm_shape(business_sf) +
  tm_dots()

```

- point-in-plot count, test for NA
```{r}
#| code-fold: true
#| code-summary: "show code"
hexagon_sf$`BUSINESS_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, business_sf))
summary(hexagon_sf$BUSINESS_COUNT)

# hexagon_sf[hexagon_sf$BUSINESS_COUNT > 30,]

# hexagon_sf[is.na(hexagon_sf$BUSINESS_COUNT),]

```


## 2.2 Repeat steps for various other factors:

::: {.panel-tabset}

## Entertainment 

```{r}
#| code-fold: true
#| code-summary: "show code"
entertn_sf <- st_read(dsn = "data/geospatial",
                      layer = "entertn")
# st_crs(entertn_sf)

hexagon_sf$`ENTERTAIN_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, entertn_sf))
summary(hexagon_sf$ENTERTAIN_COUNT)
```


## FNB 

```{r}
#| code-fold: true
#| code-summary: "show code"
fnb_sf <- st_read(dsn = "data/geospatial",
                      layer = "F&B")
# st_crs(fnb_sf)

hexagon_sf$`FNB_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, fnb_sf))
summary(hexagon_sf$FNB_COUNT)
```



## Finserv

```{r}
#| code-fold: true
#| code-summary: "show code"
finserv_sf <- st_read(dsn = "data/geospatial",
                      layer = "FinServ")
# st_crs(finserv_sf)


hexagon_sf$`FINSERV_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, finserv_sf))
summary(hexagon_sf$FINSERV_COUNT)
```

## Leisure

```{r}
#| code-fold: true
#| code-summary: "show code"
leisure_sf <- st_read(dsn = "data/geospatial",
                      layer = "Liesure&Recreation")
# st_crs(leisure_sf)


hexagon_sf$`LEISURE_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, leisure_sf))
summary(hexagon_sf$LEISURE_COUNT)
```

## Retail

```{r}
#| code-fold: true
#| code-summary: "show code"
retail_sf <- st_read(dsn = "data/geospatial",
                      layer = "Retails")
# st_crs(retail_sf)


hexagon_sf$`RETAIL_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, retail_sf))
summary(hexagon_sf$RETAIL_COUNT)
```

## Train Station Exit 

```{r}
#| code-fold: true
#| code-summary: "show code"
mrt_exit_sf <- st_read(dsn = "data/geospatial",
                      layer = "Train_Station_Exit_Layer")  %>%
  st_transform(crs=3414)
st_crs(mrt_exit_sf)


hexagon_sf$`MRT_EXIT_COUNT`<- lengths(
  st_intersects(
    hexagon_sf, mrt_exit_sf))
summary(hexagon_sf$MRT_EXIT_COUNT)
```


## Data
- First, let's write hexagon_sf to rds 
```{r}
write_rds(hexagon_sf, "data/rds/hexagon_features.rds")
head(hexagon_sf)
```
- Now we perform plot of layers
```{r}
tmap_mode("view")

tm <- tm_shape(hexagon_sf, group="FINSERV_COUNT") +
 tm_borders(group="FINSERV_COUNT") + 
 tm_fill(col = "FINSERV_COUNT", 
         palette = "Greens",
         style = "jenks",
         group="FINSERV_COUNT") + 
  
 tm_shape(hexagon_sf, group="FNB_COUNT") +
 tm_borders(group="FNB_COUNT") + 
 tm_fill(col = "FNB_COUNT", 
         palette = "Reds",
         style = "jenks",
         group="FNB_COUNT") + 
  
 tm_shape(hexagon_sf, group="ENTERTAIN_COUNT") +
 tm_borders(group="ENTERTAIN_COUNT") + 
 tm_fill(col = "ENTERTAIN_COUNT", 
         palette = "Blues",
         style = "jenks",
         group="ENTERTAIN_COUNT") + 
  
 tm_shape(hexagon_sf, group="LEISURE_COUNT") +
 tm_borders(group="LEISURE_COUNT") + 
 tm_fill(col = "LEISURE_COUNT", 
         palette = "Purples",
         style = "jenks",
         group="LEISURE_COUNT")


tm %>% 
  tmap_leaflet() %>%
  hideGroup(c("FNB_COUNT", "ENTERTAIN_COUNT", "LEISURE_COUNT")) %>%
  addLayersControl(
    overlayGroups = c("FINSERV_COUNT", "FNB_COUNT",
                      "ENTERTAIN_COUNT", "LEISURE_COUNT"),
    options = layersControlOptions(collapsed = FALSE),
    position = "topleft"
  )

# tmap_mode("plot")
# # tmap_options(check.and.fix = TRUE)
# tm_shape(hexagon_sf) +
#   tm_polygons() +
# tm_shape(entertn_sf) +
#   tm_dots()
# 
# tmap_mode("view")
# tm_shape(hexagon_sf[hexagon_sf$FINSERV_COUNT > 70, ]) +
#   tm_polygons() +
#   tm_shape(hexagon_sf[hexagon_sf$FNB_COUNT > 70, ]) +
#   tm_polygons()  +
#   tm_shape(hexagon_sf[hexagon_sf$ENTERTAIN_COUNT > 6, ]) +
#   tm_polygons()  +
#   tm_shape(hexagon_sf[hexagon_sf$LEISURE_COUNT > 20, ]) +
#   tm_polygons()  +
  # tm_shape(hexagon_sf[hexagon_sf$RETAIL_COUNT > 100, ]) +
  # tm_polygons()



```

:::
                    
```{r}
#| code-fold: true
#| code-summary: "show code"
# entertn_sf <- st_read(dsn = "data/geospatial",
#                       layer = "entertn")
# st_crs(entertn_sf)
# 
# fnb_sf <- st_read(dsn = "data/geospatial",
#                       layer = "F&B")
# st_crs(fnb_sf)
# 
# finserv_sf <- st_read(dsn = "data/geospatial",
#                       layer = "FinServ")
# st_crs(finserv_sf)

leisure_sf <- st_read(dsn = "data/geospatial",
                      layer = "Liesure&Recreation")
st_crs(leisure_sf)



leisure_sf <- st_read(dsn = "data/geospatial",
                      layer = "Liesure&Recreation")
st_crs(leisure_sf)

```




- read & Fix mrt
- use st_make_valid() does not work, so I sourced wdpar::st_repair_geometry [`wdpar source`](https://search.r-project.org/CRAN/refmans/wdpar/html/st_repair_geometry.html), based on [`prepr`](https://github.com/dickoa/prepr) package to repair geometries
    - thereafter we need to coerce from EPSG9001 to svy21
```{r}
#| code-fold: true
#| code-summary: "show code"
library(wdpar)

raw_mrt_sf <- st_read(dsn = "data/geospatial",
                      layer = "RapidTransitSystemStation")
mrt_sf <- st_repair_geometry(raw_mrt_sf) %>%
  st_transform(crs=3414)
st_crs(mrt_sf)


tmap_mode("plot")
# tmap_options(check.and.fix = TRUE)
tm_shape(hexagon_sf) +
  tm_polygons(col = "MRT_EXIT_COUNT", palette = "-Spectral") +
tm_shape(mrt_sf) +
  tm_dots(col='red')

```

- Largely seem to overlap;
- Based on reasoning, MRT Exits seem like a more likely source of entry points, we will use that

# 3. Spatial Interactive Models

## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

- Propulsive:
  - business_count
  - MRT_EXIT_COUNT
  - finserv count
- Attractive:
  - leisure_count
  - fnb_count
  - entertainment_count

### 3.1.P Propulsive count

```{r}
#| code-fold: true
#| code-summary: "show code"

prop_sf <- hexagon_sf %>%
  select(grid_id, BUSINESS_COUNT, FNB_COUNT, FINSERV_COUNT, MRT_EXIT_COUNT) %>%
  st_drop_geometry()
inter_zonal_flow_prop <- inter_zonal_flow %>%
  left_join(prop_sf,
            by = c("ORIGIN_HEX" = "grid_id")) %>%
  rename(P_MRT_EXIT_COUNT = MRT_EXIT_COUNT,
         P_FNB_COUNT = FNB_COUNT, 
         P_BUSINESS_COUNT = BUSINESS_COUNT)
inter_zonal_flow_prop
```


### 3.1.P Attractiveness count

```{r}
#| code-fold: true
#| code-summary: "show code"

attr_sf <- hexagon_sf %>%
  select(grid_id, ENTERTAIN_COUNT , FNB_COUNT, LEISURE_COUNT, RETAIL_COUNT, MRT_EXIT_COUNT) %>%
  st_drop_geometry()
SIM_data <- inter_zonal_flow_prop %>%
  left_join(attr_sf,
            by = c("DESTIN_HEX" = "grid_id")) %>%
  rename(A_MRT_EXIT_COUNT = MRT_EXIT_COUNT,
         A_FNB_COUNT = FNB_COUNT, 
         A_FINSERV_COUNT = FINSERV_COUNT,
         A_ENTERTAIN_COUNT = ENTERTAIN_COUNT, 
         A_LEISURE_COUNT = LEISURE_COUNT, 
         A_RETAIL_COUNT = RETAIL_COUNT)
SIM_data
```

- Check summary

```{r}
#| code-fold: true
#| code-summary: "show code"
summary(SIM_data)
```

- We will coerce all 0 values to 0.99

```{r}
#| code-fold: true
#| code-summary: "show code"

replace_zeroes_columns <-  c("P_BUSINESS_COUNT", "P_FNB_COUNT", "A_FINSERV_COUNT", "P_MRT_EXIT_COUNT", "A_ENTERTAIN_COUNT", "A_FNB_COUNT", "A_LEISURE_COUNT", "A_RETAIL_COUNT", "A_MRT_EXIT_COUNT")

# Assuming 'your_data' is your data frame and 'columns_to_update' is a vector of column names
# Apply a function to replace 0 with 1 in specified columns
SIM_data[, replace_zeroes_columns] <- apply(SIM_data[, replace_zeroes_columns], 2, function(x) replace(x, x == 0, 0.99))

summary(SIM_data)
```

- Write to RDS

```{r}
#| code-fold: true
#| code-summary: "show code"
write_rds(SIM_data,
          "data/rds/SIM_data_tidy.rds")
```

## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

```{r}
#| code-fold: true
#| code-summary: "show code"

uncSIM <- glm(formula = SUM_TRIPS ~ 
                log(P_BUSINESS_COUNT) + 
                log(P_FNB_COUNT) +
                log(A_FINSERV_COUNT) + 
                log(P_MRT_EXIT_COUNT) +
                log(A_ENTERTAIN_COUNT) + 
                log(A_FNB_COUNT) +
                log(A_LEISURE_COUNT) + 
                log(A_FNB_COUNT) +
                log(A_RETAIL_COUNT) + 
                log(A_MRT_EXIT_COUNT) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM

SIM_data[which(! complete.cases(SIM_data)), ]
```


## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

```{r}
#| code-fold: true
#| code-summary: "show code"
# CalcRSquared <- function(observed,estimated){
#   r <- cor(observed,estimated)
#   R2 <- r^2
#   R2
# }
# CalcRSquared(uncSIM$data$SUM_TRIPS, uncSIM$fitted.values)
# 185274
# 185252 - 22
```


## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

```{r}
#| code-fold: true
#| code-summary: "show code"

```


## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

```{r}
#| code-fold: true
#| code-summary: "show code"

```

## 3.1 Create SIM_DATA
- Combine Flow data with hexagon sf

```{r}
#| code-fold: true
#| code-summary: "show code"

```
